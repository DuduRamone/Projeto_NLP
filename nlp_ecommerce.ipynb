{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Category                                        Description\n",
      "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
      "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
      "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
      "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
      "4  Household  Incredible Gifts India Wooden Happy Birthday U...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./ecommerceDataset.csv', header=None)\n",
    "\n",
    "data.columns = ['Category', 'Description']\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Description  \\\n",
      "0  Paper Plane Design Framed Wall Hanging Motivat...   \n",
      "1  SAF 'Floral' Framed Painting (Wood, 30 inch x ...   \n",
      "2  SAF 'UV Textured Modern Art Print Framed' Pain...   \n",
      "3  SAF Flower Print Framed Painting (Synthetic, 1...   \n",
      "4  Incredible Gifts India Wooden Happy Birthday U...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  paper plane design framed wall hanging motivat...  \n",
      "1  saf floral framed painting wood 30 inch x 10 i...  \n",
      "2  saf uv textured modern art print framed painti...  \n",
      "3  saf flower print framed painting synthetic 135...  \n",
      "4  incredible gifts india wooden happy birthday u...  \n"
     ]
    }
   ],
   "source": [
    "# Removendo pontuação e convertendo para minúsculas\n",
    "data['cleaned_text'] = data['Description'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar o resultado\n",
    "print(data[['Description', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eduar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eduar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baixar pacotes necessários\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text  \\\n",
      "0  paper plane design framed wall hanging motivat...   \n",
      "1  saf floral framed painting wood 30 inch x 10 i...   \n",
      "2  saf uv textured modern art print framed painti...   \n",
      "3  saf flower print framed painting synthetic 135...   \n",
      "4  incredible gifts india wooden happy birthday u...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [paper, plane, design, framed, wall, hanging, ...  \n",
      "1  [saf, floral, framed, painting, wood, 30, inch...  \n",
      "2  [saf, uv, textured, modern, art, print, framed...  \n",
      "3  [saf, flower, print, framed, painting, synthet...  \n",
      "4  [incredible, gifts, india, wooden, happy, birt...  \n"
     ]
    }
   ],
   "source": [
    "# Definir as stopwords em inglês\n",
    "custom_stop_words = set(stopwords.words('english'))\n",
    "custom_stop_words.update(['x', '1', 'also', 'product', 'one'])  # Adiciona \"x\" às stopwords\n",
    "\n",
    "# Função para tokenizar e remover stopwords\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in custom_stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Garantir que todos os valores na coluna 'cleaned_text' sejam strings\n",
    "data['cleaned_text'] = data['cleaned_text'].astype(str)\n",
    "\n",
    "# Preencher valores nulos com uma string vazia\n",
    "data['cleaned_text'] = data['cleaned_text'].fillna('')\n",
    "\n",
    "# Agora podemos aplicar a tokenização e remoção de stopwords\n",
    "data['tokens'] = data['cleaned_text'].apply(tokenize_and_remove_stopwords)\n",
    "\n",
    "# Exibindo as primeiras linhas para verificar o resultado\n",
    "print(data[['cleaned_text', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treinamento: 30255\n",
      "Tamanho do conjunto de validação: 10085\n",
      "Tamanho do conjunto de teste: 10085\n"
     ]
    }
   ],
   "source": [
    "# Divisão inicial em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['tokens'], data['Category'], test_size=0.2, random_state=35)\n",
    "\n",
    "# Dividindo ainda mais o conjunto de treino para criar um conjunto de validação (80% treino, 20% validação)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=35)  # 0.25*0.8 = 0.2\n",
    "\n",
    "# Exibindo o tamanho de cada conjunto\n",
    "print(f\"Tamanho do conjunto de treinamento: {len(X_train)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - exploração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de classes:\n",
      "Category\n",
      "Household                 19313\n",
      "Books                     11820\n",
      "Electronics               10621\n",
      "Clothing & Accessories     8671\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contagem de instâncias por classe (categoria)\n",
    "class_counts = data['Category'].value_counts()\n",
    "\n",
    "# Exibindo a contagem de cada classe\n",
    "print(\"Contagem de classes:\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas descritivas sobre o comprimento dos textos:\n",
      "count    50425.000000\n",
      "mean        74.449420\n",
      "std         91.731621\n",
      "min          1.000000\n",
      "25%         26.000000\n",
      "50%         52.000000\n",
      "75%         98.000000\n",
      "max       4504.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculando o comprimento de cada descrição em termos de número de tokens\n",
    "data['text_length'] = data['tokens'].apply(len)\n",
    "\n",
    "# Exibindo estatísticas descritivas sobre o comprimento dos textos\n",
    "print(\"Estatísticas descritivas sobre o comprimento dos textos:\")\n",
    "print(data['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando a distribuição das classes\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title('Distribuição de Classes')\n",
    "plt.xlabel('Categoria')\n",
    "plt.ylabel('Contagem')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palavras mais comuns:\n",
      "[('book', 12317), ('use', 11834), ('set', 11796), ('easy', 11239), ('quality', 11099), ('made', 10484), ('design', 10117), ('size', 10069), ('home', 9824), ('author', 9736)]\n"
     ]
    }
   ],
   "source": [
    "# Juntando todos os tokens em uma única lista\n",
    "all_tokens = [token for tokens in data['tokens'] for token in tokens]\n",
    "\n",
    "# Calculando a frequência das palavras\n",
    "word_freq = Counter(all_tokens)\n",
    "\n",
    "# Exibindo as 10 palavras mais comuns\n",
    "print(\"10 palavras mais comuns:\")\n",
    "print(word_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categoria: Books\n",
      "Exemplo de descrições: ['inner engineering a yogis guide to joy about the author sadhguru jaggi vasudevsadhguru is a yogi mystic and visionary who established the isha foundation a nonprofit dedicated to the cultivation of human potential he belongs to no particular tradition and his scientific methods for selftransformation have universal appeal sadhguru has been an inuential voice at global forums including the united nations and the world economic forum he is the author of inner engineering spiegel  grau 2016 and makes his residence in india and tennessee for more visit innerengineeringcomsadhguru jaggi vasudevsadhguru is a yogi mystic and visionary who established the isha foundation a nonprofit dedicated to the cultivation of human potential he belongs to no particular tradition and his scientific methods for selftransformation have universal appeal sadhguru has been an inuential voice at global forums including the united nations and the world economic forum he is the author of inner engineering spiegel  grau 2016 and makes his residence in india and tennessee for more visit innerengineeringcom', 'muslims and missionaries in premutiny india']\n",
      "\n",
      "Categoria: Clothing & Accessories\n",
      "Exemplo de descrições: ['woopower 36m pink for 024m baby trouser top sets3pcs boy girl hooded topsstriped pantshairband outfits36mpink size name36m colourpink description100 brand new and type children setgender unisexfor season autumn springcoloroptional pink greensize table 7080 90 100cminchsize tops length bust pants length age70 32 1260 46 1811 37 1457 36m80 34 1339 48 1890 39 1535 612m90 36 1417 52 2047 41 1614 1218m100 38 1496 54 2126 44 1732 1824mnote1 due to the light and screen difference the items color may be slightly different from the pictures2 please allow 12 cm differences due to manual measurement3 the age is just formend please kindly refer to your kids actual height and the size chart before buyingbidding thanks4 if your kid is chubby wemend choosing a larger size thanks', 'amour butterfly design sunglasses for girls 6 years  sku16  amour butterfly design sunglasses to give full protection very light weight highly durable its safe for kids eyes and give full eye protection against harmful uv rays']\n",
      "\n",
      "Categoria: Electronics\n",
      "Exemplo de descrições: ['dell 195v334amp 65w laptop adapter without power cord design features of dell laptop  power adapter  65 watt no power cable the dell 65watt inspiron ac power adapter helps you to charge dell laptops with screen size ranging from 13inches to 17inches the inspiron power adapter provides you with continuous power supply the adapter is lightweight for ease of use the 3pronged plug design of the dell inspiron laptop adapter prevents voltage drop you can easily plug it into any wall outlet to deliver ac power to your laptop', 'bluetooth dongle usb csr 40 adapter receiver transfer wireless adapter for pc computer laptop supports windows 10 81 8 7 vista xp  upgraded version']\n",
      "\n",
      "Categoria: Household\n",
      "Exemplo de descrições: ['paper plane design framed wall hanging motivational office decor art prints 87 x 87 inch  set of 4 painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it this is an special series of paintings which makes your wall very beautiful and gives a royal touch this painting is ready to hang you would be proud to possess this unique painting that is a niche apart we use only the most modern and efficient printing technology on our prints with only the and inks and precision epson roland and hp printers this innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime we print solely with topnotch 100 inks to achieve brilliant and true colours due to their high level of uv resistance our prints retain their beautiful colours for many years add colour and style to your living space with this digitally printed painting some are for pleasure and some for eternal blissso bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and familyit would be treasured forever by whoever your lucky recipient is liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home office or any room', 'saf floral framed painting wood 30 inch x 10 inch special effect uv print textured sao297 painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it this is an special series of paintings which makes your wall very beautiful and gives a royal touch a perfect gift for your special ones']\n"
     ]
    }
   ],
   "source": [
    "# Agrupando dados por categoria e visualizando algumas amostras\n",
    "grouped_data = data.groupby('Category')['cleaned_text'].apply(list)\n",
    "\n",
    "# Exibindo algumas amostras de cada categoria\n",
    "for category, texts in grouped_data.items():\n",
    "    print(f\"\\nCategoria: {category}\")\n",
    "    print(f\"Exemplo de descrições: {texts[:2]}\")  # Exibe duas descrições por categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Modelo Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma da matriz Bag-of-Words: (30255, 95952)\n"
     ]
    }
   ],
   "source": [
    "# Criando um vetor de contagem de palavras (Bag-of-Words)\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_bow = vectorizer_bow.fit_transform(X_train.apply(lambda x: ' '.join(x)))  # Transformando lista de tokens em string\n",
    "X_val_bow = vectorizer_bow.transform(X_val.apply(lambda x: ' '.join(x)))\n",
    "X_test_bow = vectorizer_bow.transform(X_test.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Exibindo a forma da matriz resultante\n",
    "print(f\"Forma da matriz Bag-of-Words: {X_train_bow.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma da matriz TF-IDF: (30255, 95952)\n"
     ]
    }
   ],
   "source": [
    "# Criando um vetor de TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train.apply(lambda x: ' '.join(x)))  # Transformando lista de tokens em string\n",
    "X_val_tfidf = vectorizer_tfidf.transform(X_val.apply(lambda x: ' '.join(x)))\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Exibindo a forma da matriz resultante\n",
    "print(f\"Forma da matriz TF-IDF: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempenho do modelo Naive Bayes com Bag-of-Words:\n",
      "Acurácia: 0.9528011898859693\n",
      "Precisão: 0.9530192347427643\n",
      "Recall: 0.9528011898859693\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo Naive Bayes com Bag-of-Words\n",
    "model_nb_bow = MultinomialNB()\n",
    "model_nb_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de validação\n",
    "y_pred_val_bow = model_nb_bow.predict(X_val_bow)\n",
    "\n",
    "# Avaliação do modelo Naive Bayes com Bag-of-Words\n",
    "accuracy_bow = accuracy_score(y_val, y_pred_val_bow)\n",
    "precision_bow = precision_score(y_val, y_pred_val_bow, average='weighted')\n",
    "recall_bow = recall_score(y_val, y_pred_val_bow, average='weighted')\n",
    "\n",
    "print(\"Desempenho do modelo Naive Bayes com Bag-of-Words:\")\n",
    "print(f\"Acurácia: {accuracy_bow}\")\n",
    "print(f\"Precisão: {precision_bow}\")\n",
    "print(f\"Recall: {recall_bow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo Logistic Regression com TF-IDF\n",
    "model_lr_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de validação\n",
    "y_pred_val_tfidf = model_lr_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "# Avaliação do modelo Logistic Regression com TF-IDF\n",
    "accuracy_tfidf = accuracy_score(y_val, y_pred_val_tfidf)\n",
    "precision_tfidf = precision_score(y_val, y_pred_val_tfidf, average='weighted')\n",
    "recall_tfidf = recall_score(y_val, y_pred_val_tfidf, average='weighted')\n",
    "\n",
    "print(\"Desempenho do modelo Logistic Regression com TF-IDF:\")\n",
    "print(f\"Acurácia: {accuracy_tfidf}\")\n",
    "print(f\"Precisão: {precision_tfidf}\")\n",
    "print(f\"Recall: {recall_tfidf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC para Naive Bayes com Bag-of-Words: 0.9841170629853995\n",
      "AUC-ROC para Logistic Regression com TF-IDF: 0.9947759122650979\n"
     ]
    }
   ],
   "source": [
    "# Calculando AUC-ROC para Naive Bayes com Bag-of-Words\n",
    "roc_auc_bow = roc_auc_score(y_val, model_nb_bow.predict_proba(X_val_bow), multi_class='ovr')\n",
    "\n",
    "print(f\"AUC-ROC para Naive Bayes com Bag-of-Words: {roc_auc_bow}\")\n",
    "\n",
    "# Calculando AUC-ROC para Logistic Regression com TF-IDF\n",
    "roc_auc_tfidf = roc_auc_score(y_val, model_lr_tfidf.predict_proba(X_val_tfidf), multi_class='ovr')\n",
    "\n",
    "print(f\"AUC-ROC para Logistic Regression com TF-IDF: {roc_auc_tfidf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Modelos Avançados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from langchain import LLMChain\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18c5689a9a547c1950fd5ece6999c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\4064288429.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5198, 'grad_norm': 9.228694915771484, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 1.492, 'grad_norm': 9.310762405395508, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4398, 'grad_norm': 7.498249530792236, 'learning_rate': 3e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3845, 'grad_norm': 7.429069519042969, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3425, 'grad_norm': 6.678196907043457, 'learning_rate': 5e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 58\u001b[0m\n\u001b[0;32m     50\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     51\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                         \u001b[38;5;66;03m# O modelo BERT\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                  \u001b[38;5;66;03m# Argumentos de treinamento\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,         \u001b[38;5;66;03m# Dados de treinamento\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,            \u001b[38;5;66;03m# Dados de validação\u001b[39;00m\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Treinando o modelo\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Avaliação no conjunto de validação\u001b[39;00m\n\u001b[0;32m     61\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2295\u001b[0m ):\n\u001b[0;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3328\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3328\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3330\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3333\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3334\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1695\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1695\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1709\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:584\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    574\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 584\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    506\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    512\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 514\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    524\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    437\u001b[0m )\n\u001b[1;32m--> 439\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# Carregar o modelo BERT pré-treinado para classificação de sequências\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(data['Category'].unique()))\n",
    "\n",
    "# Preparar os dados para o modelo BERT\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Classe personalizada para o Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Aqui convertemos para LongTensor\n",
    "        return item\n",
    "\n",
    "# Tokenizar os textos\n",
    "X_train_encodings = tokenizer(X_train.apply(lambda x: ' '.join(x)).tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "X_val_encodings = tokenizer(X_val.apply(lambda x: ' '.join(x)).tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "X_test_encodings = tokenizer(X_test.apply(lambda x: ' '.join(x)).tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "# Criando os datasets personalizados com os rótulos codificados\n",
    "train_dataset = CustomDataset(X_train_encodings, y_train_encoded)\n",
    "val_dataset = CustomDataset(X_val_encodings, y_val_encoded)\n",
    "\n",
    "# Definir o Trainer do Huggingface para treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Diretório para salvar os resultados\n",
    "    num_train_epochs=3,              # Número de épocas\n",
    "    per_device_train_batch_size=8,   # Tamanho do lote por dispositivo (GPU/CPU)\n",
    "    per_device_eval_batch_size=16,   # Tamanho do lote de avaliação\n",
    "    warmup_steps=500,                # Número de passos para aquecimento\n",
    "    weight_decay=0.01,               # Decaimento de peso\n",
    "    logging_dir='./logs',            # Diretório para logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # O modelo BERT\n",
    "    args=training_args,                  # Argumentos de treinamento\n",
    "    train_dataset=train_dataset,         # Dados de treinamento\n",
    "    eval_dataset=val_dataset,            # Dados de validação\n",
    ")\n",
    "\n",
    "# Treinando o modelo\n",
    "trainer.train()\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Resultados da avaliação: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb0f697de2d446f8814fa80d21db791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\eduar\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7e424be0f34a84b1be7162227f5633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aac83f418345429e451d4a1aef6999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05b42419e8a42c99ecdf367061f1e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf39e0625cf9487ab9ded44f3b8b0996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f48f397de2a4a738b866d6d6b5103a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3446, 'grad_norm': 9.775323867797852, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 1.3413, 'grad_norm': 17.582576751708984, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3686, 'grad_norm': 8.922935485839844, 'learning_rate': 3e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3805, 'grad_norm': 10.681228637695312, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.375, 'grad_norm': 10.72651195526123, 'learning_rate': 5e-06, 'epoch': 0.01}\n",
      "{'loss': 1.2939, 'grad_norm': 10.95237922668457, 'learning_rate': 6e-06, 'epoch': 0.02}\n",
      "{'loss': 1.4404, 'grad_norm': 12.402175903320312, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 1.415, 'grad_norm': 11.784027099609375, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 1.3356, 'grad_norm': 9.709861755371094, 'learning_rate': 9e-06, 'epoch': 0.02}\n",
      "{'loss': 1.2569, 'grad_norm': 5.5762939453125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.4106, 'grad_norm': 6.084354400634766, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.03}\n",
      "{'loss': 1.3306, 'grad_norm': 6.2657880783081055, 'learning_rate': 1.2e-05, 'epoch': 0.03}\n",
      "{'loss': 1.4148, 'grad_norm': 10.862422943115234, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.03}\n",
      "{'loss': 1.2463, 'grad_norm': 6.816244125366211, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 1.3182, 'grad_norm': 4.71729040145874, 'learning_rate': 1.5e-05, 'epoch': 0.04}\n",
      "{'loss': 1.3573, 'grad_norm': 11.713764190673828, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.04}\n",
      "{'loss': 1.3362, 'grad_norm': 6.75066614151001, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.04}\n",
      "{'loss': 1.2209, 'grad_norm': 5.863975524902344, 'learning_rate': 1.8e-05, 'epoch': 0.05}\n",
      "{'loss': 1.3323, 'grad_norm': 9.154423713684082, 'learning_rate': 1.9e-05, 'epoch': 0.05}\n",
      "{'loss': 1.4162, 'grad_norm': 15.400392532348633, 'learning_rate': 2e-05, 'epoch': 0.05}\n",
      "{'loss': 1.2795, 'grad_norm': 11.766520500183105, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.2987, 'grad_norm': 11.377364158630371, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3175, 'grad_norm': 25.019927978515625, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
      "{'loss': 1.1934, 'grad_norm': 18.12610626220703, 'learning_rate': 2.4e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3111, 'grad_norm': 12.49265193939209, 'learning_rate': 2.5e-05, 'epoch': 0.07}\n",
      "{'loss': 1.1397, 'grad_norm': 15.099048614501953, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.07}\n",
      "{'loss': 1.171, 'grad_norm': 19.01799964904785, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8514, 'grad_norm': 7.495792865753174, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.07}\n",
      "{'loss': 1.0868, 'grad_norm': 21.210073471069336, 'learning_rate': 2.9e-05, 'epoch': 0.08}\n",
      "{'loss': 1.0614, 'grad_norm': 18.292892456054688, 'learning_rate': 3e-05, 'epoch': 0.08}\n",
      "{'loss': 1.4096, 'grad_norm': 81.36141204833984, 'learning_rate': 3.1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.0865, 'grad_norm': 43.19581604003906, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.08}\n",
      "{'loss': 0.9709, 'grad_norm': 48.81555938720703, 'learning_rate': 3.3e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7904, 'grad_norm': 8.580218315124512, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8726, 'grad_norm': 53.36304473876953, 'learning_rate': 3.5e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8511, 'grad_norm': 50.301979064941406, 'learning_rate': 3.6e-05, 'epoch': 0.1}\n",
      "{'loss': 0.6898, 'grad_norm': 10.748419761657715, 'learning_rate': 3.7e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7205, 'grad_norm': 26.626161575317383, 'learning_rate': 3.8e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7766, 'grad_norm': 21.69649314880371, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.1}\n",
      "{'loss': 0.5677, 'grad_norm': 32.3154411315918, 'learning_rate': 4e-05, 'epoch': 0.11}\n",
      "{'loss': 0.695, 'grad_norm': 47.83252716064453, 'learning_rate': 4.1e-05, 'epoch': 0.11}\n",
      "{'loss': 0.5293, 'grad_norm': 30.029848098754883, 'learning_rate': 4.2e-05, 'epoch': 0.11}\n",
      "{'loss': 0.9247, 'grad_norm': 59.318458557128906, 'learning_rate': 4.3e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8102, 'grad_norm': 2.206850290298462, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1851, 'grad_norm': 90.71208190917969, 'learning_rate': 4.5e-05, 'epoch': 0.12}\n",
      "{'loss': 1.0448, 'grad_norm': 37.95363998413086, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1098, 'grad_norm': 21.37680435180664, 'learning_rate': 4.7e-05, 'epoch': 0.12}\n",
      "{'loss': 0.8066, 'grad_norm': 9.111467361450195, 'learning_rate': 4.8e-05, 'epoch': 0.13}\n",
      "{'loss': 0.7165, 'grad_norm': 46.652099609375, 'learning_rate': 4.9e-05, 'epoch': 0.13}\n",
      "{'loss': 0.8801, 'grad_norm': 42.53818130493164, 'learning_rate': 5e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6201, 'grad_norm': 50.9267463684082, 'learning_rate': 4.992921857304643e-05, 'epoch': 0.13}\n",
      "{'loss': 0.6834, 'grad_norm': 15.26224422454834, 'learning_rate': 4.9858437146092866e-05, 'epoch': 0.14}\n",
      "{'loss': 0.9087, 'grad_norm': 65.18449401855469, 'learning_rate': 4.9787655719139295e-05, 'epoch': 0.14}\n",
      "{'loss': 0.7542, 'grad_norm': 5.834545135498047, 'learning_rate': 4.971687429218573e-05, 'epoch': 0.14}\n",
      "{'loss': 0.8892, 'grad_norm': 54.874656677246094, 'learning_rate': 4.9646092865232165e-05, 'epoch': 0.15}\n",
      "{'loss': 0.5551, 'grad_norm': 11.23776912689209, 'learning_rate': 4.95753114382786e-05, 'epoch': 0.15}\n",
      "{'loss': 0.6815, 'grad_norm': 37.54221725463867, 'learning_rate': 4.950453001132503e-05, 'epoch': 0.15}\n",
      "{'loss': 0.5513, 'grad_norm': 22.465438842773438, 'learning_rate': 4.9433748584371465e-05, 'epoch': 0.15}\n",
      "{'loss': 0.5146, 'grad_norm': 27.204214096069336, 'learning_rate': 4.936296715741789e-05, 'epoch': 0.16}\n",
      "{'loss': 0.504, 'grad_norm': 27.83167839050293, 'learning_rate': 4.929218573046433e-05, 'epoch': 0.16}\n",
      "{'loss': 0.8451, 'grad_norm': 17.947086334228516, 'learning_rate': 4.922140430351076e-05, 'epoch': 0.16}\n",
      "{'loss': 0.6165, 'grad_norm': 88.3292465209961, 'learning_rate': 4.915062287655719e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7164, 'grad_norm': 18.7758731842041, 'learning_rate': 4.907984144960363e-05, 'epoch': 0.17}\n",
      "{'loss': 0.688, 'grad_norm': 32.09331512451172, 'learning_rate': 4.900906002265006e-05, 'epoch': 0.17}\n",
      "{'loss': 0.5098, 'grad_norm': 9.890817642211914, 'learning_rate': 4.893827859569649e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1901, 'grad_norm': 2.2047805786132812, 'learning_rate': 4.886749716874293e-05, 'epoch': 0.17}\n",
      "{'loss': 0.4008, 'grad_norm': 36.30622863769531, 'learning_rate': 4.8796715741789355e-05, 'epoch': 0.18}\n",
      "{'loss': 0.6585, 'grad_norm': 19.65186882019043, 'learning_rate': 4.872593431483579e-05, 'epoch': 0.18}\n",
      "{'loss': 0.6138, 'grad_norm': 27.53866958618164, 'learning_rate': 4.865515288788222e-05, 'epoch': 0.18}\n",
      "{'loss': 0.4116, 'grad_norm': 42.20771408081055, 'learning_rate': 4.8584371460928654e-05, 'epoch': 0.19}\n",
      "{'loss': 0.5893, 'grad_norm': 37.384037017822266, 'learning_rate': 4.851359003397509e-05, 'epoch': 0.19}\n",
      "{'loss': 0.666, 'grad_norm': 31.692251205444336, 'learning_rate': 4.8442808607021525e-05, 'epoch': 0.19}\n",
      "{'loss': 0.6965, 'grad_norm': 62.80598831176758, 'learning_rate': 4.8372027180067953e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3148, 'grad_norm': 29.44853401184082, 'learning_rate': 4.830124575311438e-05, 'epoch': 0.2}\n",
      "{'loss': 0.5118, 'grad_norm': 31.266904830932617, 'learning_rate': 4.823046432616082e-05, 'epoch': 0.2}\n",
      "{'loss': 0.251, 'grad_norm': 66.41404724121094, 'learning_rate': 4.8159682899207246e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6429, 'grad_norm': 27.803590774536133, 'learning_rate': 4.808890147225368e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3783, 'grad_norm': 7.557194232940674, 'learning_rate': 4.8018120045300116e-05, 'epoch': 0.21}\n",
      "{'loss': 0.9195, 'grad_norm': 3.578453540802002, 'learning_rate': 4.794733861834655e-05, 'epoch': 0.21}\n",
      "{'loss': 0.3285, 'grad_norm': 51.99365234375, 'learning_rate': 4.787655719139298e-05, 'epoch': 0.21}\n",
      "{'loss': 0.6518, 'grad_norm': 16.16646957397461, 'learning_rate': 4.7805775764439416e-05, 'epoch': 0.21}\n",
      "{'loss': 0.3931, 'grad_norm': 35.21487808227539, 'learning_rate': 4.7734994337485844e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7102, 'grad_norm': 25.969318389892578, 'learning_rate': 4.766421291053228e-05, 'epoch': 0.22}\n",
      "{'loss': 0.4861, 'grad_norm': 12.898377418518066, 'learning_rate': 4.759343148357871e-05, 'epoch': 0.22}\n",
      "{'loss': 0.4363, 'grad_norm': 51.427391052246094, 'learning_rate': 4.752265005662514e-05, 'epoch': 0.22}\n",
      "{'loss': 0.2419, 'grad_norm': 48.72909927368164, 'learning_rate': 4.745186862967158e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1403, 'grad_norm': 6.289373397827148, 'learning_rate': 4.7381087202718014e-05, 'epoch': 0.23}\n",
      "{'loss': 0.5302, 'grad_norm': 19.589658737182617, 'learning_rate': 4.731030577576444e-05, 'epoch': 0.23}\n",
      "{'loss': 0.4336, 'grad_norm': 0.11347148567438126, 'learning_rate': 4.723952434881088e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5254, 'grad_norm': 0.8899373412132263, 'learning_rate': 4.7168742921857306e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5294, 'grad_norm': 18.612760543823242, 'learning_rate': 4.709796149490374e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1956, 'grad_norm': 12.72055721282959, 'learning_rate': 4.702718006795017e-05, 'epoch': 0.24}\n",
      "{'loss': 0.6921, 'grad_norm': 29.42409896850586, 'learning_rate': 4.6956398640996605e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3696, 'grad_norm': 0.2408427596092224, 'learning_rate': 4.6885617214043034e-05, 'epoch': 0.25}\n",
      "{'loss': 0.5669, 'grad_norm': 18.49643898010254, 'learning_rate': 4.6814835787089476e-05, 'epoch': 0.25}\n",
      "{'loss': 0.6084, 'grad_norm': 11.831917762756348, 'learning_rate': 4.6744054360135905e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3121, 'grad_norm': 28.88669776916504, 'learning_rate': 4.667327293318233e-05, 'epoch': 0.26}\n",
      "{'loss': 0.2921, 'grad_norm': 5.948423385620117, 'learning_rate': 4.660249150622877e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3048, 'grad_norm': 6.768523216247559, 'learning_rate': 4.65317100792752e-05, 'epoch': 0.26}\n",
      "{'loss': 0.4202, 'grad_norm': 0.7377161979675293, 'learning_rate': 4.646092865232163e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5986, 'grad_norm': 0.7078990936279297, 'learning_rate': 4.639014722536806e-05, 'epoch': 0.27}\n",
      "{'loss': 0.5079, 'grad_norm': 13.602083206176758, 'learning_rate': 4.6319365798414496e-05, 'epoch': 0.27}\n",
      "{'loss': 0.818, 'grad_norm': 53.54669952392578, 'learning_rate': 4.624858437146093e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4712, 'grad_norm': 37.995243072509766, 'learning_rate': 4.617780294450737e-05, 'epoch': 0.27}\n",
      "{'loss': 0.3303, 'grad_norm': 19.055198669433594, 'learning_rate': 4.6107021517553795e-05, 'epoch': 0.28}\n",
      "{'loss': 0.3445, 'grad_norm': 0.7253249883651733, 'learning_rate': 4.603624009060023e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4604, 'grad_norm': 0.2139139324426651, 'learning_rate': 4.596545866364666e-05, 'epoch': 0.28}\n",
      "{'loss': 0.493, 'grad_norm': 21.463245391845703, 'learning_rate': 4.5894677236693094e-05, 'epoch': 0.29}\n",
      "{'loss': 0.6021, 'grad_norm': 92.06228637695312, 'learning_rate': 4.582389580973952e-05, 'epoch': 0.29}\n",
      "{'loss': 0.4783, 'grad_norm': 13.55153751373291, 'learning_rate': 4.575311438278596e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3261, 'grad_norm': 9.947293281555176, 'learning_rate': 4.5682332955832394e-05, 'epoch': 0.29}\n",
      "{'loss': 0.5884, 'grad_norm': 18.52472496032715, 'learning_rate': 4.561155152887883e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4842, 'grad_norm': 0.32734033465385437, 'learning_rate': 4.554077010192526e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3545, 'grad_norm': 0.37875568866729736, 'learning_rate': 4.546998867497169e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0936, 'grad_norm': 0.1716432273387909, 'learning_rate': 4.539920724801812e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3899, 'grad_norm': 104.81021118164062, 'learning_rate': 4.5328425821064557e-05, 'epoch': 0.31}\n",
      "{'loss': 0.583, 'grad_norm': 64.24027252197266, 'learning_rate': 4.5257644394110985e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3332, 'grad_norm': 0.6950465440750122, 'learning_rate': 4.518686296715742e-05, 'epoch': 0.31}\n",
      "{'loss': 0.5635, 'grad_norm': 51.691612243652344, 'learning_rate': 4.5116081540203856e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1842, 'grad_norm': 0.31491169333457947, 'learning_rate': 4.5045300113250284e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4712, 'grad_norm': 4.4428019523620605, 'learning_rate': 4.497451868629672e-05, 'epoch': 0.32}\n",
      "{'loss': 0.3563, 'grad_norm': 107.66310119628906, 'learning_rate': 4.490373725934315e-05, 'epoch': 0.32}\n",
      "{'loss': 0.2666, 'grad_norm': 0.2892645299434662, 'learning_rate': 4.483295583238958e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2519, 'grad_norm': 115.85205841064453, 'learning_rate': 4.476217440543601e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5951, 'grad_norm': 0.4534722864627838, 'learning_rate': 4.469139297848245e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2051, 'grad_norm': 0.3479296565055847, 'learning_rate': 4.462061155152888e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5912, 'grad_norm': 83.01960754394531, 'learning_rate': 4.454983012457532e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3719, 'grad_norm': 0.40966513752937317, 'learning_rate': 4.4479048697621746e-05, 'epoch': 0.34}\n",
      "{'loss': 0.2109, 'grad_norm': 4.572901725769043, 'learning_rate': 4.440826727066818e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3016, 'grad_norm': 0.34560203552246094, 'learning_rate': 4.433748584371461e-05, 'epoch': 0.34}\n",
      "{'loss': 0.2309, 'grad_norm': 0.6064440608024597, 'learning_rate': 4.4266704416761046e-05, 'epoch': 0.35}\n",
      "{'loss': 0.2451, 'grad_norm': 0.1241910383105278, 'learning_rate': 4.4195922989807474e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3104, 'grad_norm': 0.47113701701164246, 'learning_rate': 4.412514156285391e-05, 'epoch': 0.35}\n",
      "{'loss': 0.6624, 'grad_norm': 78.53790283203125, 'learning_rate': 4.405436013590034e-05, 'epoch': 0.35}\n",
      "{'loss': 0.2838, 'grad_norm': 7.909386157989502, 'learning_rate': 4.398357870894677e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2097, 'grad_norm': 4.11733865737915, 'learning_rate': 4.391279728199321e-05, 'epoch': 0.36}\n",
      "{'loss': 0.5316, 'grad_norm': 0.33475399017333984, 'learning_rate': 4.3842015855039644e-05, 'epoch': 0.36}\n",
      "{'loss': 0.5038, 'grad_norm': 0.39819639921188354, 'learning_rate': 4.377123442808607e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2857, 'grad_norm': 106.84243774414062, 'learning_rate': 4.370045300113251e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3504, 'grad_norm': 9.930570602416992, 'learning_rate': 4.3629671574178936e-05, 'epoch': 0.37}\n",
      "{'loss': 0.2455, 'grad_norm': 40.526973724365234, 'learning_rate': 4.3558890147225365e-05, 'epoch': 0.37}\n",
      "{'loss': 0.5078, 'grad_norm': 49.723968505859375, 'learning_rate': 4.34881087202718e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4511, 'grad_norm': 29.188968658447266, 'learning_rate': 4.3417327293318235e-05, 'epoch': 0.38}\n",
      "{'loss': 0.2669, 'grad_norm': 13.959083557128906, 'learning_rate': 4.334654586636467e-05, 'epoch': 0.38}\n",
      "{'loss': 0.6373, 'grad_norm': 0.1816394031047821, 'learning_rate': 4.32757644394111e-05, 'epoch': 0.38}\n",
      "{'loss': 0.7007, 'grad_norm': 74.68482208251953, 'learning_rate': 4.3204983012457534e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3118, 'grad_norm': 0.21541227400302887, 'learning_rate': 4.313420158550396e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3326, 'grad_norm': 0.23569482564926147, 'learning_rate': 4.30634201585504e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4032, 'grad_norm': 0.09697473794221878, 'learning_rate': 4.299263873159683e-05, 'epoch': 0.39}\n",
      "{'loss': 0.2374, 'grad_norm': 1.3102301359176636, 'learning_rate': 4.292185730464326e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4669, 'grad_norm': 34.02079391479492, 'learning_rate': 4.28510758776897e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4961, 'grad_norm': 15.081598281860352, 'learning_rate': 4.278029445073613e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2658, 'grad_norm': 1.4137259721755981, 'learning_rate': 4.270951302378256e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3668, 'grad_norm': 1.023970603942871, 'learning_rate': 4.2638731596829e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4897, 'grad_norm': 147.7849884033203, 'learning_rate': 4.2567950169875425e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4531, 'grad_norm': 73.19483947753906, 'learning_rate': 4.249716874292186e-05, 'epoch': 0.41}\n",
      "{'loss': 0.1597, 'grad_norm': 3.6044368743896484, 'learning_rate': 4.242638731596829e-05, 'epoch': 0.42}\n",
      "{'loss': 0.5558, 'grad_norm': 207.327392578125, 'learning_rate': 4.2355605889014724e-05, 'epoch': 0.42}\n",
      "{'loss': 0.5299, 'grad_norm': 84.37837982177734, 'learning_rate': 4.228482446206116e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2441, 'grad_norm': 0.17625030875205994, 'learning_rate': 4.2214043035107595e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4262, 'grad_norm': 18.422096252441406, 'learning_rate': 4.2143261608154023e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4948, 'grad_norm': 4.353801250457764, 'learning_rate': 4.207248018120046e-05, 'epoch': 0.43}\n",
      "{'loss': 0.2634, 'grad_norm': 0.14401403069496155, 'learning_rate': 4.200169875424689e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4804, 'grad_norm': 3.5833489894866943, 'learning_rate': 4.1930917327293316e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6187, 'grad_norm': 5.250710964202881, 'learning_rate': 4.186013590033975e-05, 'epoch': 0.44}\n",
      "{'loss': 0.5697, 'grad_norm': 67.83940124511719, 'learning_rate': 4.178935447338618e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1694, 'grad_norm': 4.250053405761719, 'learning_rate': 4.171857304643262e-05, 'epoch': 0.44}\n",
      "{'loss': 0.5102, 'grad_norm': 4.565165042877197, 'learning_rate': 4.164779161947905e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4187, 'grad_norm': 0.17770862579345703, 'learning_rate': 4.1577010192525486e-05, 'epoch': 0.45}\n",
      "{'loss': 0.2923, 'grad_norm': 0.09894199669361115, 'learning_rate': 4.1506228765571914e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1967, 'grad_norm': 0.457596093416214, 'learning_rate': 4.143544733861835e-05, 'epoch': 0.45}\n",
      "{'loss': 0.6286, 'grad_norm': 0.21731559932231903, 'learning_rate': 4.136466591166478e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3759, 'grad_norm': 142.27825927734375, 'learning_rate': 4.129388448471121e-05, 'epoch': 0.46}\n",
      "{'loss': 0.3428, 'grad_norm': 174.2095947265625, 'learning_rate': 4.122310305775764e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2784, 'grad_norm': 4.211745738983154, 'learning_rate': 4.115232163080408e-05, 'epoch': 0.46}\n",
      "{'loss': 0.8899, 'grad_norm': 205.429443359375, 'learning_rate': 4.108154020385051e-05, 'epoch': 0.47}\n",
      "{'loss': 0.1891, 'grad_norm': 4.315051078796387, 'learning_rate': 4.101075877689695e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2276, 'grad_norm': 0.16448922455310822, 'learning_rate': 4.0939977349943376e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2923, 'grad_norm': 0.10339691489934921, 'learning_rate': 4.086919592298981e-05, 'epoch': 0.47}\n",
      "{'loss': 0.2507, 'grad_norm': 0.06478934735059738, 'learning_rate': 4.079841449603624e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4769, 'grad_norm': 0.33321571350097656, 'learning_rate': 4.0727633069082675e-05, 'epoch': 0.48}\n",
      "{'loss': 0.726, 'grad_norm': 7.576812744140625, 'learning_rate': 4.0656851642129104e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1697, 'grad_norm': 5.5864033699035645, 'learning_rate': 4.058607021517554e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2524, 'grad_norm': 5.226665496826172, 'learning_rate': 4.0515288788221975e-05, 'epoch': 0.49}\n",
      "{'loss': 0.1433, 'grad_norm': 0.17763589322566986, 'learning_rate': 4.044450736126841e-05, 'epoch': 0.49}\n",
      "{'loss': 0.5019, 'grad_norm': 3.8424127101898193, 'learning_rate': 4.037372593431484e-05, 'epoch': 0.49}\n",
      "{'loss': 0.2328, 'grad_norm': 0.36151477694511414, 'learning_rate': 4.030294450736127e-05, 'epoch': 0.49}\n",
      "{'loss': 0.4179, 'grad_norm': 8.041609764099121, 'learning_rate': 4.02321630804077e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3597, 'grad_norm': 49.958744049072266, 'learning_rate': 4.016138165345413e-05, 'epoch': 0.5}\n",
      "{'loss': 0.174, 'grad_norm': 0.20206980407238007, 'learning_rate': 4.0090600226500566e-05, 'epoch': 0.5}\n",
      "{'loss': 0.1108, 'grad_norm': 0.7418351173400879, 'learning_rate': 4.0019818799547e-05, 'epoch': 0.51}\n",
      "{'loss': 0.2664, 'grad_norm': 2.0191473960876465, 'learning_rate': 3.994903737259344e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4272, 'grad_norm': 148.92967224121094, 'learning_rate': 3.9878255945639865e-05, 'epoch': 0.51}\n",
      "{'loss': 0.8186, 'grad_norm': 2.239328384399414, 'learning_rate': 3.98074745186863e-05, 'epoch': 0.51}\n",
      "{'loss': 0.4036, 'grad_norm': 33.53887939453125, 'learning_rate': 3.973669309173273e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2749, 'grad_norm': 0.14644095301628113, 'learning_rate': 3.9665911664779164e-05, 'epoch': 0.52}\n",
      "{'loss': 0.4384, 'grad_norm': 0.16151750087738037, 'learning_rate': 3.959513023782559e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2252, 'grad_norm': 0.20045709609985352, 'learning_rate': 3.952434881087203e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2582, 'grad_norm': 0.4124965965747833, 'learning_rate': 3.9453567383918464e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3431, 'grad_norm': 42.2959098815918, 'learning_rate': 3.93827859569649e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.169, 'grad_norm': 0.1054735854268074, 'learning_rate': 3.931200453001133e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2185, 'grad_norm': 0.09062626957893372, 'learning_rate': 3.924122310305776e-05, 'epoch': 0.53}\n",
      "{'loss': 0.3652, 'grad_norm': 103.51316833496094, 'learning_rate': 3.917044167610419e-05, 'epoch': 0.54}\n",
      "{'loss': 0.5206, 'grad_norm': 14.529224395751953, 'learning_rate': 3.9099660249150627e-05, 'epoch': 0.54}\n",
      "{'loss': 0.4214, 'grad_norm': 3.6054282188415527, 'learning_rate': 3.9028878822197055e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3651, 'grad_norm': 10.151164054870605, 'learning_rate': 3.895809739524349e-05, 'epoch': 0.54}\n",
      "{'loss': 0.2915, 'grad_norm': 92.3759994506836, 'learning_rate': 3.8887315968289926e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2797, 'grad_norm': 85.5000228881836, 'learning_rate': 3.881653454133636e-05, 'epoch': 0.55}\n",
      "{'loss': 0.337, 'grad_norm': 0.19369475543498993, 'learning_rate': 3.874575311438279e-05, 'epoch': 0.55}\n",
      "{'loss': 0.2562, 'grad_norm': 0.939833402633667, 'learning_rate': 3.867497168742922e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3092, 'grad_norm': 56.19624328613281, 'learning_rate': 3.860419026047565e-05, 'epoch': 0.56}\n",
      "{'loss': 0.6264, 'grad_norm': 1.2432386875152588, 'learning_rate': 3.853340883352208e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0984, 'grad_norm': 0.19765101373195648, 'learning_rate': 3.846262740656852e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3378, 'grad_norm': 0.22331355512142181, 'learning_rate': 3.8391845979614946e-05, 'epoch': 0.57}\n",
      "{'loss': 0.4009, 'grad_norm': 15.40855598449707, 'learning_rate': 3.832106455266138e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3787, 'grad_norm': 0.14666472375392914, 'learning_rate': 3.8250283125707816e-05, 'epoch': 0.57}\n",
      "{'loss': 0.1337, 'grad_norm': 0.16433866322040558, 'learning_rate': 3.817950169875425e-05, 'epoch': 0.57}\n",
      "{'loss': 0.4519, 'grad_norm': 3.8981640338897705, 'learning_rate': 3.810872027180068e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1481, 'grad_norm': 0.16217747330665588, 'learning_rate': 3.8037938844847115e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3096, 'grad_norm': 3.7830240726470947, 'learning_rate': 3.7967157417893544e-05, 'epoch': 0.58}\n",
      "{'loss': 0.4806, 'grad_norm': 46.1562385559082, 'learning_rate': 3.789637599093998e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1452, 'grad_norm': 6.696364402770996, 'learning_rate': 3.782559456398641e-05, 'epoch': 0.59}\n",
      "{'loss': 0.5542, 'grad_norm': 0.2217126339673996, 'learning_rate': 3.775481313703284e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3348, 'grad_norm': 57.07168960571289, 'learning_rate': 3.768403171007928e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3196, 'grad_norm': 8.972027778625488, 'learning_rate': 3.7613250283125714e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3718, 'grad_norm': 10.145245552062988, 'learning_rate': 3.754246885617214e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3737, 'grad_norm': 82.04524230957031, 'learning_rate': 3.747168742921858e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3433, 'grad_norm': 3.8335225582122803, 'learning_rate': 3.7400906002265006e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1941, 'grad_norm': 0.13080382347106934, 'learning_rate': 3.733012457531144e-05, 'epoch': 0.61}\n",
      "{'loss': 0.1947, 'grad_norm': 0.09084944427013397, 'learning_rate': 3.725934314835787e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6123, 'grad_norm': 9.340538024902344, 'learning_rate': 3.7188561721404305e-05, 'epoch': 0.61}\n",
      "{'loss': 0.5298, 'grad_norm': 45.57250213623047, 'learning_rate': 3.711778029445074e-05, 'epoch': 0.61}\n",
      "{'loss': 0.4418, 'grad_norm': 0.29762327671051025, 'learning_rate': 3.704699886749717e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2724, 'grad_norm': 101.79906463623047, 'learning_rate': 3.6976217440543604e-05, 'epoch': 0.62}\n",
      "{'loss': 0.5168, 'grad_norm': 101.78596496582031, 'learning_rate': 3.690543601359003e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0918, 'grad_norm': 4.281327247619629, 'learning_rate': 3.683465458663647e-05, 'epoch': 0.62}\n",
      "{'loss': 0.2103, 'grad_norm': 0.4015271067619324, 'learning_rate': 3.67638731596829e-05, 'epoch': 0.63}\n",
      "{'loss': 0.4444, 'grad_norm': 14.824542045593262, 'learning_rate': 3.669309173272933e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0449, 'grad_norm': 0.14188727736473083, 'learning_rate': 3.662231030577577e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2828, 'grad_norm': 118.63336181640625, 'learning_rate': 3.65515288788222e-05, 'epoch': 0.63}\n",
      "{'loss': 0.2052, 'grad_norm': 0.24409471452236176, 'learning_rate': 3.648074745186863e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1847, 'grad_norm': 0.17465026676654816, 'learning_rate': 3.6409966024915067e-05, 'epoch': 0.64}\n",
      "{'loss': 0.4551, 'grad_norm': 151.0079803466797, 'learning_rate': 3.6339184597961495e-05, 'epoch': 0.64}\n",
      "{'loss': 0.519, 'grad_norm': 48.42841720581055, 'learning_rate': 3.626840317100793e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1687, 'grad_norm': 0.360918790102005, 'learning_rate': 3.619762174405436e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3621, 'grad_norm': 3.8785195350646973, 'learning_rate': 3.6126840317100794e-05, 'epoch': 0.65}\n",
      "{'loss': 0.4754, 'grad_norm': 9.186028480529785, 'learning_rate': 3.605605889014723e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3237, 'grad_norm': 0.1346662938594818, 'learning_rate': 3.5985277463193665e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0973, 'grad_norm': 0.13135677576065063, 'learning_rate': 3.5914496036240093e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3087, 'grad_norm': 0.08677305281162262, 'learning_rate': 3.584371460928653e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4597, 'grad_norm': 0.38213208317756653, 'learning_rate': 3.577293318233296e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3865, 'grad_norm': 112.63909912109375, 'learning_rate': 3.570215175537939e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1696, 'grad_norm': 0.07081159949302673, 'learning_rate': 3.563137032842582e-05, 'epoch': 0.67}\n",
      "{'loss': 0.2674, 'grad_norm': 128.86378479003906, 'learning_rate': 3.556058890147225e-05, 'epoch': 0.67}\n",
      "{'loss': 0.1897, 'grad_norm': 81.12857818603516, 'learning_rate': 3.5489807474518685e-05, 'epoch': 0.67}\n",
      "{'loss': 0.5328, 'grad_norm': 7.521778583526611, 'learning_rate': 3.541902604756512e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1611, 'grad_norm': 0.14711424708366394, 'learning_rate': 3.5348244620611556e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2165, 'grad_norm': 0.11345337331295013, 'learning_rate': 3.5277463193657984e-05, 'epoch': 0.68}\n",
      "{'loss': 0.4086, 'grad_norm': 23.654624938964844, 'learning_rate': 3.520668176670442e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2112, 'grad_norm': 0.08550781011581421, 'learning_rate': 3.513590033975085e-05, 'epoch': 0.69}\n",
      "{'loss': 0.4612, 'grad_norm': 9.506948471069336, 'learning_rate': 3.506511891279728e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3281, 'grad_norm': 3.6415677070617676, 'learning_rate': 3.499433748584371e-05, 'epoch': 0.69}\n",
      "{'loss': 0.2628, 'grad_norm': 0.16887636482715607, 'learning_rate': 3.492355605889015e-05, 'epoch': 0.7}\n",
      "{'loss': 0.234, 'grad_norm': 0.2313460260629654, 'learning_rate': 3.485277463193658e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0349, 'grad_norm': 0.7492981553077698, 'learning_rate': 3.478199320498302e-05, 'epoch': 0.7}\n",
      "{'loss': 0.163, 'grad_norm': 144.82345581054688, 'learning_rate': 3.4711211778029446e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2427, 'grad_norm': 3.84250545501709, 'learning_rate': 3.464043035107588e-05, 'epoch': 0.71}\n",
      "{'loss': 0.4747, 'grad_norm': 119.8486557006836, 'learning_rate': 3.456964892412231e-05, 'epoch': 0.71}\n",
      "{'loss': 0.164, 'grad_norm': 0.10634199529886246, 'learning_rate': 3.4498867497168745e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2748, 'grad_norm': 3.7625162601470947, 'learning_rate': 3.4428086070215174e-05, 'epoch': 0.71}\n",
      "{'loss': 0.5298, 'grad_norm': 0.2342226505279541, 'learning_rate': 3.435730464326161e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3598, 'grad_norm': 23.264734268188477, 'learning_rate': 3.4286523216308045e-05, 'epoch': 0.72}\n",
      "{'loss': 0.2599, 'grad_norm': 6.429520606994629, 'learning_rate': 3.421574178935448e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3647, 'grad_norm': 0.19219139218330383, 'learning_rate': 3.414496036240091e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3765, 'grad_norm': 0.9867826104164124, 'learning_rate': 3.4074178935447344e-05, 'epoch': 0.73}\n",
      "{'loss': 0.5196, 'grad_norm': 61.52173614501953, 'learning_rate': 3.400339750849377e-05, 'epoch': 0.73}\n",
      "{'loss': 0.1946, 'grad_norm': 0.6931930780410767, 'learning_rate': 3.39326160815402e-05, 'epoch': 0.73}\n",
      "{'loss': 0.1199, 'grad_norm': 0.24401095509529114, 'learning_rate': 3.3861834654586636e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1501, 'grad_norm': 0.2067757248878479, 'learning_rate': 3.379105322763307e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2613, 'grad_norm': 0.11330056190490723, 'learning_rate': 3.372027180067951e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3873, 'grad_norm': 0.09006716310977936, 'learning_rate': 3.3649490373725935e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2691, 'grad_norm': 0.16362349689006805, 'learning_rate': 3.357870894677237e-05, 'epoch': 0.75}\n",
      "{'loss': 0.247, 'grad_norm': 0.16307377815246582, 'learning_rate': 3.35079275198188e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1626, 'grad_norm': 0.12039166688919067, 'learning_rate': 3.3437146092865234e-05, 'epoch': 0.75}\n",
      "{'loss': 0.5028, 'grad_norm': 25.996065139770508, 'learning_rate': 3.336636466591166e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2928, 'grad_norm': 0.09578794240951538, 'learning_rate': 3.32955832389581e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0866, 'grad_norm': 0.21947836875915527, 'learning_rate': 3.3224801812004533e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1668, 'grad_norm': 4.100590705871582, 'learning_rate': 3.315402038505097e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2838, 'grad_norm': 0.14031140506267548, 'learning_rate': 3.30832389580974e-05, 'epoch': 0.76}\n",
      "{'loss': 0.3561, 'grad_norm': 3.814033031463623, 'learning_rate': 3.301245753114383e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2845, 'grad_norm': 0.11030074954032898, 'learning_rate': 3.294167610419026e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3978, 'grad_norm': 0.12256643921136856, 'learning_rate': 3.2870894677236696e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2991, 'grad_norm': 0.1216907724738121, 'learning_rate': 3.2800113250283125e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2381, 'grad_norm': 0.16033978760242462, 'learning_rate': 3.272933182332956e-05, 'epoch': 0.78}\n",
      "{'loss': 0.4242, 'grad_norm': 0.12052836269140244, 'learning_rate': 3.265855039637599e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3824, 'grad_norm': 0.44312068819999695, 'learning_rate': 3.2587768969422424e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3094, 'grad_norm': 54.031612396240234, 'learning_rate': 3.251698754246886e-05, 'epoch': 0.79}\n",
      "{'loss': 0.5737, 'grad_norm': 0.26802825927734375, 'learning_rate': 3.2446206115515295e-05, 'epoch': 0.79}\n",
      "{'loss': 0.1528, 'grad_norm': 0.42165422439575195, 'learning_rate': 3.237542468856172e-05, 'epoch': 0.79}\n",
      "{'loss': 0.1495, 'grad_norm': 0.11179843544960022, 'learning_rate': 3.230464326160815e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2171, 'grad_norm': 0.11242467164993286, 'learning_rate': 3.223386183465459e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1027, 'grad_norm': 31.56453514099121, 'learning_rate': 3.2163080407701016e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4475, 'grad_norm': 0.08223351836204529, 'learning_rate': 3.209229898074745e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4011, 'grad_norm': 93.7540054321289, 'learning_rate': 3.2021517553793886e-05, 'epoch': 0.8}\n",
      "{'loss': 0.424, 'grad_norm': 0.10516992211341858, 'learning_rate': 3.195073612684032e-05, 'epoch': 0.81}\n",
      "{'loss': 0.5024, 'grad_norm': 0.1531337946653366, 'learning_rate': 3.187995469988675e-05, 'epoch': 0.81}\n",
      "{'loss': 0.1703, 'grad_norm': 0.8517729043960571, 'learning_rate': 3.1809173272933185e-05, 'epoch': 0.81}\n",
      "{'loss': 0.2995, 'grad_norm': 50.371150970458984, 'learning_rate': 3.1738391845979614e-05, 'epoch': 0.81}\n",
      "{'loss': 0.2831, 'grad_norm': 0.1777825802564621, 'learning_rate': 3.166761041902605e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3349, 'grad_norm': 3.712249279022217, 'learning_rate': 3.159682899207248e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5846, 'grad_norm': 51.16025161743164, 'learning_rate': 3.152604756511891e-05, 'epoch': 0.82}\n",
      "{'loss': 0.3479, 'grad_norm': 33.649539947509766, 'learning_rate': 3.145526613816535e-05, 'epoch': 0.82}\n",
      "{'loss': 0.143, 'grad_norm': 0.31768345832824707, 'learning_rate': 3.1384484711211784e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2285, 'grad_norm': 0.1868467777967453, 'learning_rate': 3.131370328425821e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2725, 'grad_norm': 0.21055959165096283, 'learning_rate': 3.124292185730465e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3637, 'grad_norm': 0.26570066809654236, 'learning_rate': 3.1172140430351076e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2001, 'grad_norm': 0.3158338665962219, 'learning_rate': 3.110135900339751e-05, 'epoch': 0.84}\n",
      "{'loss': 0.219, 'grad_norm': 0.16516603529453278, 'learning_rate': 3.103057757644394e-05, 'epoch': 0.84}\n",
      "{'loss': 0.138, 'grad_norm': 0.10993028432130814, 'learning_rate': 3.0959796149490375e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2822, 'grad_norm': 0.1536262482404709, 'learning_rate': 3.088901472253681e-05, 'epoch': 0.85}\n",
      "{'loss': 0.2777, 'grad_norm': 0.587552547454834, 'learning_rate': 3.0818233295583246e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1971, 'grad_norm': 13.211061477661133, 'learning_rate': 3.0747451868629674e-05, 'epoch': 0.85}\n",
      "{'loss': 0.6265, 'grad_norm': 4.81873083114624, 'learning_rate': 3.06766704416761e-05, 'epoch': 0.85}\n",
      "{'loss': 0.1092, 'grad_norm': 0.19771708548069, 'learning_rate': 3.060588901472254e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3211, 'grad_norm': 0.4583522379398346, 'learning_rate': 3.053510758776897e-05, 'epoch': 0.86}\n",
      "{'loss': 0.4648, 'grad_norm': 81.97109985351562, 'learning_rate': 3.0464326160815405e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3216, 'grad_norm': 0.11036936193704605, 'learning_rate': 3.0393544733861834e-05, 'epoch': 0.86}\n",
      "{'loss': 0.2619, 'grad_norm': 0.23296666145324707, 'learning_rate': 3.032276330690827e-05, 'epoch': 0.87}\n",
      "{'loss': 0.3979, 'grad_norm': 3.7187843322753906, 'learning_rate': 3.0251981879954698e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4129, 'grad_norm': 5.383266448974609, 'learning_rate': 3.0181200453001137e-05, 'epoch': 0.87}\n",
      "{'loss': 0.2845, 'grad_norm': 0.20504941046237946, 'learning_rate': 3.0110419026047565e-05, 'epoch': 0.88}\n",
      "{'loss': 0.321, 'grad_norm': 14.555464744567871, 'learning_rate': 3.0039637599094e-05, 'epoch': 0.88}\n",
      "{'loss': 0.1911, 'grad_norm': 0.11887145787477493, 'learning_rate': 2.996885617214043e-05, 'epoch': 0.88}\n",
      "{'loss': 0.287, 'grad_norm': 0.10714632272720337, 'learning_rate': 2.9898074745186864e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3504, 'grad_norm': 0.12135863304138184, 'learning_rate': 2.9827293318233296e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3088, 'grad_norm': 0.17057600617408752, 'learning_rate': 2.975651189127973e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3534, 'grad_norm': 0.14932750165462494, 'learning_rate': 2.968573046432616e-05, 'epoch': 0.89}\n",
      "{'loss': 0.2343, 'grad_norm': 16.880168914794922, 'learning_rate': 2.9614949037372595e-05, 'epoch': 0.89}\n",
      "{'loss': 0.2989, 'grad_norm': 29.01273536682129, 'learning_rate': 2.9544167610419027e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2571, 'grad_norm': 3.3712949752807617, 'learning_rate': 2.9473386183465463e-05, 'epoch': 0.9}\n",
      "{'loss': 0.4488, 'grad_norm': 3.7861900329589844, 'learning_rate': 2.940260475651189e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2182, 'grad_norm': 37.288299560546875, 'learning_rate': 2.9331823329558326e-05, 'epoch': 0.9}\n",
      "{'loss': 0.1965, 'grad_norm': 16.169166564941406, 'learning_rate': 2.9261041902604758e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3215, 'grad_norm': 0.19308997690677643, 'learning_rate': 2.9190260475651194e-05, 'epoch': 0.91}\n",
      "{'loss': 0.1836, 'grad_norm': 0.3346523940563202, 'learning_rate': 2.9119479048697622e-05, 'epoch': 0.91}\n",
      "{'loss': 0.254, 'grad_norm': 3.8290743827819824, 'learning_rate': 2.9048697621744054e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4553, 'grad_norm': 0.17800527811050415, 'learning_rate': 2.897791619479049e-05, 'epoch': 0.92}\n",
      "{'loss': 0.1412, 'grad_norm': 0.3681153953075409, 'learning_rate': 2.8907134767836918e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2581, 'grad_norm': 3.729020833969116, 'learning_rate': 2.8836353340883353e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2159, 'grad_norm': 0.16507193446159363, 'learning_rate': 2.8765571913929785e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2592, 'grad_norm': 0.12169553339481354, 'learning_rate': 2.869479048697622e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2578, 'grad_norm': 24.55499839782715, 'learning_rate': 2.862400906002265e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3372, 'grad_norm': 32.249324798583984, 'learning_rate': 2.8553227633069084e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2179, 'grad_norm': 0.6708424091339111, 'learning_rate': 2.8482446206115516e-05, 'epoch': 0.94}\n",
      "{'loss': 0.1358, 'grad_norm': 0.1330845206975937, 'learning_rate': 2.841166477916195e-05, 'epoch': 0.94}\n",
      "{'loss': 0.5135, 'grad_norm': 3.844358205795288, 'learning_rate': 2.834088335220838e-05, 'epoch': 0.94}\n",
      "{'loss': 0.1343, 'grad_norm': 0.16720378398895264, 'learning_rate': 2.8270101925254815e-05, 'epoch': 0.94}\n",
      "{'loss': 0.127, 'grad_norm': 31.05569076538086, 'learning_rate': 2.8199320498301247e-05, 'epoch': 0.95}\n",
      "{'loss': 0.3676, 'grad_norm': 0.10982341319322586, 'learning_rate': 2.8128539071347683e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0908, 'grad_norm': 0.2150111049413681, 'learning_rate': 2.805775764439411e-05, 'epoch': 0.95}\n",
      "{'loss': 0.252, 'grad_norm': 0.13145309686660767, 'learning_rate': 2.7986976217440546e-05, 'epoch': 0.95}\n",
      "{'loss': 0.2818, 'grad_norm': 0.09914632886648178, 'learning_rate': 2.791619479048698e-05, 'epoch': 0.96}\n",
      "{'loss': 0.5312, 'grad_norm': 59.402523040771484, 'learning_rate': 2.7845413363533414e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1591, 'grad_norm': 0.29305675625801086, 'learning_rate': 2.7774631936579842e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4569, 'grad_norm': 0.09479120373725891, 'learning_rate': 2.7703850509626277e-05, 'epoch': 0.97}\n",
      "{'loss': 0.5659, 'grad_norm': 0.21057142317295074, 'learning_rate': 2.763306908267271e-05, 'epoch': 0.97}\n",
      "{'loss': 0.308, 'grad_norm': 0.11572837084531784, 'learning_rate': 2.7562287655719138e-05, 'epoch': 0.97}\n",
      "{'loss': 0.2943, 'grad_norm': 111.4981689453125, 'learning_rate': 2.7491506228765573e-05, 'epoch': 0.97}\n",
      "{'loss': 0.1424, 'grad_norm': 0.5543766617774963, 'learning_rate': 2.7420724801812002e-05, 'epoch': 0.98}\n",
      "{'loss': 0.1551, 'grad_norm': 107.83717346191406, 'learning_rate': 2.734994337485844e-05, 'epoch': 0.98}\n",
      "{'loss': 0.1343, 'grad_norm': 39.951866149902344, 'learning_rate': 2.727916194790487e-05, 'epoch': 0.98}\n",
      "{'loss': 0.3371, 'grad_norm': 6.015037536621094, 'learning_rate': 2.7208380520951304e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0379, 'grad_norm': 6.836967945098877, 'learning_rate': 2.7137599093997733e-05, 'epoch': 0.99}\n",
      "{'loss': 0.2697, 'grad_norm': 0.23267404735088348, 'learning_rate': 2.7066817667044168e-05, 'epoch': 0.99}\n",
      "{'loss': 0.2362, 'grad_norm': 0.9520237445831299, 'learning_rate': 2.69960362400906e-05, 'epoch': 0.99}\n",
      "{'loss': 0.2453, 'grad_norm': 1.198978066444397, 'learning_rate': 2.6925254813137035e-05, 'epoch': 0.99}\n",
      "{'loss': 0.1732, 'grad_norm': 4.108977794647217, 'learning_rate': 2.6854473386183464e-05, 'epoch': 1.0}\n",
      "{'loss': 0.5739, 'grad_norm': 3.7676825523376465, 'learning_rate': 2.67836919592299e-05, 'epoch': 1.0}\n",
      "{'loss': 0.1748, 'grad_norm': 3.816476821899414, 'learning_rate': 2.671291053227633e-05, 'epoch': 1.0}\n",
      "{'loss': 0.2772, 'grad_norm': 3.9713847637176514, 'learning_rate': 2.6642129105322766e-05, 'epoch': 1.0}\n",
      "{'loss': 0.1887, 'grad_norm': 20.770111083984375, 'learning_rate': 2.6571347678369195e-05, 'epoch': 1.01}\n",
      "{'loss': 0.1935, 'grad_norm': 0.1420575976371765, 'learning_rate': 2.650056625141563e-05, 'epoch': 1.01}\n",
      "{'loss': 0.3523, 'grad_norm': 7.956558704376221, 'learning_rate': 2.6429784824462062e-05, 'epoch': 1.01}\n",
      "{'loss': 0.2401, 'grad_norm': 1.049712896347046, 'learning_rate': 2.6359003397508497e-05, 'epoch': 1.02}\n",
      "{'loss': 0.1782, 'grad_norm': 0.43421855568885803, 'learning_rate': 2.6288221970554926e-05, 'epoch': 1.02}\n",
      "{'loss': 0.1332, 'grad_norm': 0.15603600442409515, 'learning_rate': 2.621744054360136e-05, 'epoch': 1.02}\n",
      "{'loss': 0.3552, 'grad_norm': 0.1513047218322754, 'learning_rate': 2.6146659116647793e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0905, 'grad_norm': 0.10012578219175339, 'learning_rate': 2.607587768969423e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0515, 'grad_norm': 0.13388030230998993, 'learning_rate': 2.6005096262740657e-05, 'epoch': 1.03}\n",
      "{'loss': 0.223, 'grad_norm': 0.08893006294965744, 'learning_rate': 2.593431483578709e-05, 'epoch': 1.03}\n",
      "{'loss': 0.1067, 'grad_norm': 0.09671773761510849, 'learning_rate': 2.5863533408833524e-05, 'epoch': 1.03}\n",
      "{'loss': 0.2657, 'grad_norm': 35.97545623779297, 'learning_rate': 2.5792751981879953e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1263, 'grad_norm': 77.08486938476562, 'learning_rate': 2.5721970554926388e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1914, 'grad_norm': 0.1463261991739273, 'learning_rate': 2.565118912797282e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1846, 'grad_norm': 0.06271485239267349, 'learning_rate': 2.5580407701019255e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3864, 'grad_norm': 7.572669982910156, 'learning_rate': 2.5509626274065684e-05, 'epoch': 1.05}\n",
      "{'loss': 0.3335, 'grad_norm': 49.4463005065918, 'learning_rate': 2.543884484711212e-05, 'epoch': 1.05}\n",
      "{'loss': 0.1765, 'grad_norm': 1.1662901639938354, 'learning_rate': 2.536806342015855e-05, 'epoch': 1.05}\n",
      "{'loss': 0.1689, 'grad_norm': 0.12960278987884521, 'learning_rate': 2.5297281993204986e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0207, 'grad_norm': 0.12134923040866852, 'learning_rate': 2.5226500566251415e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2399, 'grad_norm': 44.143455505371094, 'learning_rate': 2.515571913929785e-05, 'epoch': 1.06}\n",
      "{'loss': 0.251, 'grad_norm': 0.13803499937057495, 'learning_rate': 2.5084937712344282e-05, 'epoch': 1.06}\n",
      "{'loss': 0.1511, 'grad_norm': 0.13990062475204468, 'learning_rate': 2.5014156285390718e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0127, 'grad_norm': 0.09318297356367111, 'learning_rate': 2.4943374858437146e-05, 'epoch': 1.07}\n",
      "{'loss': 0.2275, 'grad_norm': 0.18259671330451965, 'learning_rate': 2.4872593431483578e-05, 'epoch': 1.07}\n",
      "{'loss': 0.245, 'grad_norm': 0.09424556791782379, 'learning_rate': 2.4801812004530013e-05, 'epoch': 1.07}\n",
      "{'loss': 0.1978, 'grad_norm': 28.327905654907227, 'learning_rate': 2.4731030577576445e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0737, 'grad_norm': 0.17814812064170837, 'learning_rate': 2.4660249150622877e-05, 'epoch': 1.08}\n",
      "{'loss': 0.1829, 'grad_norm': 0.11550885438919067, 'learning_rate': 2.458946772366931e-05, 'epoch': 1.08}\n",
      "{'loss': 0.301, 'grad_norm': 19.250314712524414, 'learning_rate': 2.4518686296715744e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0442, 'grad_norm': 0.0652916431427002, 'learning_rate': 2.4447904869762176e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2215, 'grad_norm': 0.07053101062774658, 'learning_rate': 2.4377123442808608e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0338, 'grad_norm': 1.6547843217849731, 'learning_rate': 2.430634201585504e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2518, 'grad_norm': 0.15649636089801788, 'learning_rate': 2.4235560588901472e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2482, 'grad_norm': 0.0684979259967804, 'learning_rate': 2.4164779161947907e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2448, 'grad_norm': 0.06683529168367386, 'learning_rate': 2.409399773499434e-05, 'epoch': 1.1}\n",
      "{'loss': 0.1762, 'grad_norm': 0.1243925616145134, 'learning_rate': 2.402321630804077e-05, 'epoch': 1.1}\n",
      "{'loss': 0.1957, 'grad_norm': 0.04909134656190872, 'learning_rate': 2.3952434881087203e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3509, 'grad_norm': 0.11882135272026062, 'learning_rate': 2.388165345413364e-05, 'epoch': 1.11}\n",
      "{'loss': 0.2311, 'grad_norm': 1.0719736814498901, 'learning_rate': 2.381087202718007e-05, 'epoch': 1.11}\n",
      "{'loss': 0.1161, 'grad_norm': 0.116443932056427, 'learning_rate': 2.3740090600226502e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3158, 'grad_norm': 0.08225574344396591, 'learning_rate': 2.3669309173272934e-05, 'epoch': 1.12}\n",
      "{'loss': 0.1004, 'grad_norm': 0.10933816432952881, 'learning_rate': 2.359852774631937e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2927, 'grad_norm': 0.12567655742168427, 'learning_rate': 2.3527746319365798e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2282, 'grad_norm': 3.814349412918091, 'learning_rate': 2.345696489241223e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2357, 'grad_norm': 12.37624454498291, 'learning_rate': 2.3386183465458665e-05, 'epoch': 1.13}\n",
      "{'loss': 0.237, 'grad_norm': 0.516783595085144, 'learning_rate': 2.3315402038505097e-05, 'epoch': 1.13}\n",
      "{'loss': 0.2108, 'grad_norm': 7.894204616546631, 'learning_rate': 2.324462061155153e-05, 'epoch': 1.13}\n",
      "{'loss': 0.2629, 'grad_norm': 27.7343692779541, 'learning_rate': 2.317383918459796e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1072, 'grad_norm': 22.78810691833496, 'learning_rate': 2.3103057757644396e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1229, 'grad_norm': 84.57064056396484, 'learning_rate': 2.3032276330690828e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1836, 'grad_norm': 0.08175338804721832, 'learning_rate': 2.296149490373726e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2091, 'grad_norm': 0.10321450233459473, 'learning_rate': 2.2890713476783692e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0735, 'grad_norm': 0.09542227536439896, 'learning_rate': 2.2819932049830124e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2444, 'grad_norm': 0.07117830216884613, 'learning_rate': 2.274915062287656e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2007, 'grad_norm': 0.05488351359963417, 'learning_rate': 2.267836919592299e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0054, 'grad_norm': 0.9913657307624817, 'learning_rate': 2.2607587768969423e-05, 'epoch': 1.16}\n",
      "{'loss': 0.1195, 'grad_norm': 8.966652870178223, 'learning_rate': 2.2536806342015855e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2471, 'grad_norm': 8.48537826538086, 'learning_rate': 2.246602491506229e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2753, 'grad_norm': 100.92162322998047, 'learning_rate': 2.2395243488108722e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4433, 'grad_norm': 3.8585212230682373, 'learning_rate': 2.2324462061155154e-05, 'epoch': 1.17}\n",
      "{'loss': 0.1475, 'grad_norm': 0.07614494860172272, 'learning_rate': 2.2253680634201586e-05, 'epoch': 1.17}\n",
      "{'loss': 0.0056, 'grad_norm': 0.0837838426232338, 'learning_rate': 2.218289920724802e-05, 'epoch': 1.17}\n",
      "{'loss': 0.2652, 'grad_norm': 1.2988402843475342, 'learning_rate': 2.2112117780294453e-05, 'epoch': 1.17}\n",
      "{'loss': 0.1335, 'grad_norm': 0.06839780509471893, 'learning_rate': 2.2041336353340885e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1239, 'grad_norm': 52.52001953125, 'learning_rate': 2.1970554926387317e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3502, 'grad_norm': 75.36604309082031, 'learning_rate': 2.189977349943375e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1612, 'grad_norm': 0.08787178993225098, 'learning_rate': 2.182899207248018e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3628, 'grad_norm': 107.66545867919922, 'learning_rate': 2.1758210645526613e-05, 'epoch': 1.19}\n",
      "{'loss': 0.2746, 'grad_norm': 28.13117790222168, 'learning_rate': 2.1687429218573045e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0585, 'grad_norm': 0.2826750874519348, 'learning_rate': 2.161664779161948e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0517, 'grad_norm': 1.1967376470565796, 'learning_rate': 2.1545866364665912e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0395, 'grad_norm': 0.058425068855285645, 'learning_rate': 2.1475084937712344e-05, 'epoch': 1.2}\n",
      "{'loss': 0.1322, 'grad_norm': 0.15344929695129395, 'learning_rate': 2.1404303510758776e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2099, 'grad_norm': 0.3169425427913666, 'learning_rate': 2.133352208380521e-05, 'epoch': 1.2}\n",
      "{'loss': 0.1279, 'grad_norm': 0.08680717647075653, 'learning_rate': 2.1262740656851643e-05, 'epoch': 1.21}\n",
      "{'loss': 0.2043, 'grad_norm': 0.042481113225221634, 'learning_rate': 2.1191959229898075e-05, 'epoch': 1.21}\n",
      "{'loss': 0.1715, 'grad_norm': 0.05058853700757027, 'learning_rate': 2.1121177802944507e-05, 'epoch': 1.21}\n",
      "{'loss': 0.247, 'grad_norm': 0.05905325338244438, 'learning_rate': 2.1050396375990942e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0034, 'grad_norm': 0.05146027356386185, 'learning_rate': 2.0979614949037374e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2895, 'grad_norm': 0.06197008863091469, 'learning_rate': 2.0908833522083806e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0115, 'grad_norm': 5.455406665802002, 'learning_rate': 2.0838052095130238e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0805, 'grad_norm': 0.08098079264163971, 'learning_rate': 2.0767270668176673e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0921, 'grad_norm': 0.06403984129428864, 'learning_rate': 2.0696489241223105e-05, 'epoch': 1.23}\n",
      "{'loss': 0.3258, 'grad_norm': 0.06738393753767014, 'learning_rate': 2.0625707814269537e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0888, 'grad_norm': 0.13288520276546478, 'learning_rate': 2.055492638731597e-05, 'epoch': 1.23}\n",
      "{'loss': 0.1392, 'grad_norm': 3.912004232406616, 'learning_rate': 2.0484144960362404e-05, 'epoch': 1.23}\n",
      "{'loss': 0.1195, 'grad_norm': 0.07099258154630661, 'learning_rate': 2.0413363533408836e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2726, 'grad_norm': 0.0660344809293747, 'learning_rate': 2.0342582106455265e-05, 'epoch': 1.24}\n",
      "{'loss': 0.2572, 'grad_norm': 16.284639358520508, 'learning_rate': 2.0271800679501697e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1435, 'grad_norm': 0.05821743234992027, 'learning_rate': 2.0201019252548132e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1493, 'grad_norm': 0.07650459557771683, 'learning_rate': 2.0130237825594564e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1939, 'grad_norm': 0.10411619395017624, 'learning_rate': 2.0059456398640996e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1145, 'grad_norm': 0.0609416700899601, 'learning_rate': 1.9988674971687428e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1137, 'grad_norm': 0.060326799750328064, 'learning_rate': 1.9917893544733863e-05, 'epoch': 1.26}\n",
      "{'loss': 0.1269, 'grad_norm': 0.10035162419080734, 'learning_rate': 1.9847112117780295e-05, 'epoch': 1.26}\n",
      "{'loss': 0.064, 'grad_norm': 0.04804890975356102, 'learning_rate': 1.9776330690826727e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0032, 'grad_norm': 0.042208231985569, 'learning_rate': 1.970554926387316e-05, 'epoch': 1.26}\n",
      "{'loss': 0.1588, 'grad_norm': 0.04239962249994278, 'learning_rate': 1.9634767836919594e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2211, 'grad_norm': 3.870882511138916, 'learning_rate': 1.9563986409966026e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3802, 'grad_norm': 9.506745338439941, 'learning_rate': 1.9493204983012458e-05, 'epoch': 1.27}\n",
      "{'loss': 0.0795, 'grad_norm': 0.07307425141334534, 'learning_rate': 1.942242355605889e-05, 'epoch': 1.27}\n",
      "{'loss': 0.2167, 'grad_norm': 3.8862030506134033, 'learning_rate': 1.9351642129105325e-05, 'epoch': 1.28}\n",
      "{'loss': 0.1879, 'grad_norm': 0.10353006422519684, 'learning_rate': 1.9280860702151757e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2466, 'grad_norm': 0.8956729173660278, 'learning_rate': 1.921007927519819e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0067, 'grad_norm': 0.06634923815727234, 'learning_rate': 1.913929784824462e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3083, 'grad_norm': 0.08124078065156937, 'learning_rate': 1.9068516421291056e-05, 'epoch': 1.29}\n",
      "{'loss': 0.274, 'grad_norm': 1.659462809562683, 'learning_rate': 1.899773499433749e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1013, 'grad_norm': 0.0754137858748436, 'learning_rate': 1.892695356738392e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1215, 'grad_norm': 0.0765538215637207, 'learning_rate': 1.8856172140430352e-05, 'epoch': 1.3}\n",
      "{'loss': 0.225, 'grad_norm': 0.08100223541259766, 'learning_rate': 1.8785390713476787e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4146, 'grad_norm': 50.93955993652344, 'learning_rate': 1.8714609286523216e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2583, 'grad_norm': 0.4044104218482971, 'learning_rate': 1.8643827859569648e-05, 'epoch': 1.3}\n",
      "{'loss': 0.2761, 'grad_norm': 0.07959763705730438, 'learning_rate': 1.857304643261608e-05, 'epoch': 1.31}\n",
      "{'loss': 0.073, 'grad_norm': 11.652044296264648, 'learning_rate': 1.8502265005662515e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2137, 'grad_norm': 4.454593658447266, 'learning_rate': 1.8431483578708947e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2385, 'grad_norm': 0.18839143216609955, 'learning_rate': 1.836070215175538e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2596, 'grad_norm': 31.230342864990234, 'learning_rate': 1.828992072480181e-05, 'epoch': 1.32}\n",
      "{'loss': 0.1652, 'grad_norm': 0.07375310361385345, 'learning_rate': 1.8219139297848246e-05, 'epoch': 1.32}\n",
      "{'loss': 0.339, 'grad_norm': 7.8110270500183105, 'learning_rate': 1.8148357870894678e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2269, 'grad_norm': 0.4400140047073364, 'learning_rate': 1.807757644394111e-05, 'epoch': 1.32}\n",
      "{'loss': 0.1386, 'grad_norm': 0.1962655484676361, 'learning_rate': 1.8006795016987542e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1209, 'grad_norm': 27.531333923339844, 'learning_rate': 1.7936013590033977e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1515, 'grad_norm': 13.159035682678223, 'learning_rate': 1.786523216308041e-05, 'epoch': 1.33}\n",
      "{'loss': 0.2141, 'grad_norm': 0.07479595392942429, 'learning_rate': 1.779445073612684e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2549, 'grad_norm': 0.06746330112218857, 'learning_rate': 1.7723669309173273e-05, 'epoch': 1.34}\n",
      "{'loss': 0.4004, 'grad_norm': 0.07479064166545868, 'learning_rate': 1.765288788221971e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2226, 'grad_norm': 0.1182858869433403, 'learning_rate': 1.758210645526614e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3436, 'grad_norm': 4.1043009757995605, 'learning_rate': 1.7511325028312572e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2405, 'grad_norm': 11.166295051574707, 'learning_rate': 1.7440543601359004e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0452, 'grad_norm': 0.14482584595680237, 'learning_rate': 1.736976217440544e-05, 'epoch': 1.35}\n",
      "{'loss': 0.2139, 'grad_norm': 0.11096145957708359, 'learning_rate': 1.729898074745187e-05, 'epoch': 1.35}\n",
      "{'loss': 0.277, 'grad_norm': 0.11871539056301117, 'learning_rate': 1.7228199320498303e-05, 'epoch': 1.36}\n",
      "{'loss': 0.2097, 'grad_norm': 96.99839782714844, 'learning_rate': 1.7157417893544735e-05, 'epoch': 1.36}\n",
      "{'loss': 0.4211, 'grad_norm': 0.10971454530954361, 'learning_rate': 1.7086636466591167e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0885, 'grad_norm': 4.51358699798584, 'learning_rate': 1.70158550396376e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0724, 'grad_norm': 0.07125687599182129, 'learning_rate': 1.694507361268403e-05, 'epoch': 1.37}\n",
      "{'loss': 0.3533, 'grad_norm': 0.07518704235553741, 'learning_rate': 1.6874292185730463e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2977, 'grad_norm': 0.09416158497333527, 'learning_rate': 1.6803510758776898e-05, 'epoch': 1.37}\n",
      "{'loss': 0.4813, 'grad_norm': 2.8705286979675293, 'learning_rate': 1.673272933182333e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1948, 'grad_norm': 3.818380117416382, 'learning_rate': 1.6661947904869762e-05, 'epoch': 1.38}\n",
      "{'loss': 0.153, 'grad_norm': 0.09320327639579773, 'learning_rate': 1.6591166477916194e-05, 'epoch': 1.38}\n",
      "{'loss': 0.1116, 'grad_norm': 100.96331787109375, 'learning_rate': 1.652038505096263e-05, 'epoch': 1.38}\n",
      "{'loss': 0.1793, 'grad_norm': 0.08927188813686371, 'learning_rate': 1.644960362400906e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1119, 'grad_norm': 3.8672075271606445, 'learning_rate': 1.6378822197055493e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1533, 'grad_norm': 0.06866511702537537, 'learning_rate': 1.6308040770101925e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1392, 'grad_norm': 0.12863776087760925, 'learning_rate': 1.623725934314836e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1911, 'grad_norm': 0.06496181339025497, 'learning_rate': 1.6166477916194792e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2163, 'grad_norm': 0.09980903565883636, 'learning_rate': 1.6095696489241224e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1054, 'grad_norm': 0.06889649480581284, 'learning_rate': 1.6024915062287656e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3411, 'grad_norm': 4.050185680389404, 'learning_rate': 1.595413363533409e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1172, 'grad_norm': 212.973876953125, 'learning_rate': 1.5883352208380523e-05, 'epoch': 1.41}\n",
      "{'loss': 0.1878, 'grad_norm': 0.7655841112136841, 'learning_rate': 1.5812570781426955e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0836, 'grad_norm': 0.07897540926933289, 'learning_rate': 1.5741789354473387e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2588, 'grad_norm': 7.2920637130737305, 'learning_rate': 1.567100792751982e-05, 'epoch': 1.41}\n",
      "{'loss': 0.32, 'grad_norm': 0.15978555381298065, 'learning_rate': 1.5600226500566254e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0876, 'grad_norm': 0.07506188005208969, 'learning_rate': 1.5529445073612683e-05, 'epoch': 1.42}\n",
      "{'loss': 0.209, 'grad_norm': 0.0697116032242775, 'learning_rate': 1.5458663646659115e-05, 'epoch': 1.42}\n",
      "{'loss': 0.1127, 'grad_norm': 0.06237385794520378, 'learning_rate': 1.538788221970555e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1279, 'grad_norm': 0.09679683297872543, 'learning_rate': 1.5317100792751982e-05, 'epoch': 1.43}\n",
      "{'loss': 0.357, 'grad_norm': 0.06881750375032425, 'learning_rate': 1.5246319365798414e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1631, 'grad_norm': 127.87450408935547, 'learning_rate': 1.5175537938844848e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0745, 'grad_norm': 0.13226422667503357, 'learning_rate': 1.510475651189128e-05, 'epoch': 1.44}\n",
      "{'loss': 0.2448, 'grad_norm': 0.18311099708080292, 'learning_rate': 1.5033975084937713e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0822, 'grad_norm': 203.09024047851562, 'learning_rate': 1.4963193657984145e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3109, 'grad_norm': 0.10541029274463654, 'learning_rate': 1.4892412231030579e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0976, 'grad_norm': 0.297211617231369, 'learning_rate': 1.482163080407701e-05, 'epoch': 1.45}\n",
      "{'loss': 0.2297, 'grad_norm': 45.498233795166016, 'learning_rate': 1.4750849377123444e-05, 'epoch': 1.45}\n",
      "{'loss': 0.2167, 'grad_norm': 0.052767883986234665, 'learning_rate': 1.4680067950169876e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0917, 'grad_norm': 0.09231863170862198, 'learning_rate': 1.460928652321631e-05, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0052, 'grad_norm': 0.06966698914766312, 'learning_rate': 1.4538505096262742e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3086, 'grad_norm': 0.06350850313901901, 'learning_rate': 1.4467723669309175e-05, 'epoch': 1.46}\n",
      "{'loss': 0.307, 'grad_norm': 30.48748207092285, 'learning_rate': 1.4396942242355607e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3006, 'grad_norm': 0.2513911724090576, 'learning_rate': 1.4326160815402039e-05, 'epoch': 1.46}\n",
      "{'loss': 0.151, 'grad_norm': 3.8852767944335938, 'learning_rate': 1.4255379388448473e-05, 'epoch': 1.47}\n",
      "{'loss': 0.2657, 'grad_norm': 0.12267719954252243, 'learning_rate': 1.4184597961494905e-05, 'epoch': 1.47}\n",
      "{'loss': 0.1555, 'grad_norm': 0.08761293441057205, 'learning_rate': 1.4113816534541338e-05, 'epoch': 1.47}\n",
      "{'loss': 0.2158, 'grad_norm': 0.07496004551649094, 'learning_rate': 1.404303510758777e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0304, 'grad_norm': 0.07517901808023453, 'learning_rate': 1.3972253680634204e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0669, 'grad_norm': 0.3366420865058899, 'learning_rate': 1.3901472253680634e-05, 'epoch': 1.48}\n",
      "{'loss': 0.3263, 'grad_norm': 0.06932612508535385, 'learning_rate': 1.3830690826727066e-05, 'epoch': 1.48}\n",
      "{'loss': 0.2689, 'grad_norm': 0.12583671510219574, 'learning_rate': 1.37599093997735e-05, 'epoch': 1.49}\n",
      "{'loss': 0.1927, 'grad_norm': 0.08143738657236099, 'learning_rate': 1.3689127972819931e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2632, 'grad_norm': 0.12197533994913101, 'learning_rate': 1.3618346545866365e-05, 'epoch': 1.49}\n",
      "{'loss': 0.3159, 'grad_norm': 3.85562801361084, 'learning_rate': 1.3547565118912797e-05, 'epoch': 1.49}\n",
      "{'loss': 0.2556, 'grad_norm': 5.1134843826293945, 'learning_rate': 1.347678369195923e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0086, 'grad_norm': 0.16449041664600372, 'learning_rate': 1.3406002265005663e-05, 'epoch': 1.5}\n",
      "{'loss': 0.4602, 'grad_norm': 8.9685640335083, 'learning_rate': 1.3335220838052096e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2455, 'grad_norm': 0.2224113792181015, 'learning_rate': 1.3264439411098528e-05, 'epoch': 1.5}\n",
      "{'loss': 0.077, 'grad_norm': 0.17468252778053284, 'learning_rate': 1.3193657984144962e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1146, 'grad_norm': 0.07131003588438034, 'learning_rate': 1.3122876557191394e-05, 'epoch': 1.51}\n",
      "{'loss': 0.3338, 'grad_norm': 3.99472975730896, 'learning_rate': 1.3052095130237827e-05, 'epoch': 1.51}\n",
      "{'loss': 0.1463, 'grad_norm': 0.1379149705171585, 'learning_rate': 1.2981313703284259e-05, 'epoch': 1.52}\n",
      "{'loss': 0.2086, 'grad_norm': 7.239543437957764, 'learning_rate': 1.2910532276330691e-05, 'epoch': 1.52}\n",
      "{'loss': 0.1984, 'grad_norm': 0.09495966881513596, 'learning_rate': 1.2839750849377125e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0694, 'grad_norm': 0.11776521056890488, 'learning_rate': 1.2768969422423557e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0859, 'grad_norm': 0.11995307356119156, 'learning_rate': 1.269818799546999e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2646, 'grad_norm': 0.06159459799528122, 'learning_rate': 1.2627406568516422e-05, 'epoch': 1.53}\n",
      "{'loss': 0.0398, 'grad_norm': 0.08013173192739487, 'learning_rate': 1.2556625141562856e-05, 'epoch': 1.53}\n",
      "{'loss': 0.1598, 'grad_norm': 0.21879927814006805, 'learning_rate': 1.2485843714609288e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2796, 'grad_norm': 6.629714012145996, 'learning_rate': 1.241506228765572e-05, 'epoch': 1.54}\n",
      "{'loss': 0.1752, 'grad_norm': 0.10181846469640732, 'learning_rate': 1.2344280860702152e-05, 'epoch': 1.54}\n",
      "{'loss': 0.1971, 'grad_norm': 6.15209436416626, 'learning_rate': 1.2273499433748585e-05, 'epoch': 1.54}\n",
      "{'loss': 0.1728, 'grad_norm': 0.3339592218399048, 'learning_rate': 1.2202718006795017e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2458, 'grad_norm': 0.25485759973526, 'learning_rate': 1.213193657984145e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3119, 'grad_norm': 89.02676391601562, 'learning_rate': 1.2061155152887883e-05, 'epoch': 1.55}\n",
      "{'loss': 0.3319, 'grad_norm': 0.09708218276500702, 'learning_rate': 1.1990373725934316e-05, 'epoch': 1.55}\n",
      "{'loss': 0.2161, 'grad_norm': 177.4730224609375, 'learning_rate': 1.1919592298980748e-05, 'epoch': 1.55}\n",
      "{'loss': 0.108, 'grad_norm': 75.18648529052734, 'learning_rate': 1.184881087202718e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2417, 'grad_norm': 0.12400080263614655, 'learning_rate': 1.1778029445073614e-05, 'epoch': 1.56}\n",
      "{'loss': 0.1537, 'grad_norm': 0.21749044954776764, 'learning_rate': 1.1707248018120046e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0576, 'grad_norm': 1.54386568069458, 'learning_rate': 1.1636466591166477e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0907, 'grad_norm': 15.622072219848633, 'learning_rate': 1.1565685164212911e-05, 'epoch': 1.57}\n",
      "{'loss': 0.4115, 'grad_norm': 3.860701560974121, 'learning_rate': 1.1494903737259343e-05, 'epoch': 1.57}\n",
      "{'loss': 0.1795, 'grad_norm': 0.07294256240129471, 'learning_rate': 1.1424122310305777e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0602, 'grad_norm': 67.1176528930664, 'learning_rate': 1.1353340883352209e-05, 'epoch': 1.58}\n",
      "{'loss': 0.2636, 'grad_norm': 0.2005285620689392, 'learning_rate': 1.1282559456398642e-05, 'epoch': 1.58}\n",
      "{'loss': 0.1751, 'grad_norm': 0.13941657543182373, 'learning_rate': 1.1211778029445074e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0048, 'grad_norm': 0.06661216169595718, 'learning_rate': 1.1140996602491508e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3309, 'grad_norm': 0.0959978923201561, 'learning_rate': 1.107021517553794e-05, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2832, 'grad_norm': 3.803710699081421, 'learning_rate': 1.0999433748584372e-05, 'epoch': 1.59}\n",
      "{'loss': 0.1298, 'grad_norm': 0.10868300497531891, 'learning_rate': 1.0928652321630803e-05, 'epoch': 1.59}\n",
      "{'loss': 0.2424, 'grad_norm': 0.0817987471818924, 'learning_rate': 1.0857870894677237e-05, 'epoch': 1.59}\n",
      "{'loss': 0.161, 'grad_norm': 0.0749945119023323, 'learning_rate': 1.0787089467723669e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0041, 'grad_norm': 0.0958242267370224, 'learning_rate': 1.0716308040770103e-05, 'epoch': 1.6}\n",
      "{'loss': 0.3795, 'grad_norm': 5.624824523925781, 'learning_rate': 1.0645526613816535e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0417, 'grad_norm': 0.11386783421039581, 'learning_rate': 1.0574745186862968e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2183, 'grad_norm': 0.054150380194187164, 'learning_rate': 1.05039637599094e-05, 'epoch': 1.61}\n",
      "{'loss': 0.2322, 'grad_norm': 0.10991019755601883, 'learning_rate': 1.0433182332955834e-05, 'epoch': 1.61}\n",
      "{'loss': 0.168, 'grad_norm': 0.14818820357322693, 'learning_rate': 1.0362400906002266e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0723, 'grad_norm': 0.11539198458194733, 'learning_rate': 1.0291619479048698e-05, 'epoch': 1.62}\n",
      "{'loss': 0.1284, 'grad_norm': 0.052013084292411804, 'learning_rate': 1.022083805209513e-05, 'epoch': 1.62}\n",
      "{'loss': 0.1827, 'grad_norm': 0.08877962827682495, 'learning_rate': 1.0150056625141563e-05, 'epoch': 1.62}\n",
      "{'loss': 0.1544, 'grad_norm': 0.23254066705703735, 'learning_rate': 1.0079275198187995e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0114, 'grad_norm': 0.07869569212198257, 'learning_rate': 1.0008493771234429e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0443, 'grad_norm': 0.6235844492912292, 'learning_rate': 9.93771234428086e-06, 'epoch': 1.63}\n",
      "{'loss': 0.0332, 'grad_norm': 0.038467131555080414, 'learning_rate': 9.866930917327294e-06, 'epoch': 1.63}\n",
      "{'loss': 0.1013, 'grad_norm': 24.657421112060547, 'learning_rate': 9.796149490373726e-06, 'epoch': 1.63}\n",
      "{'loss': 0.2889, 'grad_norm': 68.0243148803711, 'learning_rate': 9.72536806342016e-06, 'epoch': 1.64}\n",
      "{'loss': 0.1785, 'grad_norm': 0.0675218477845192, 'learning_rate': 9.654586636466592e-06, 'epoch': 1.64}\n",
      "{'loss': 0.1873, 'grad_norm': 0.0862351730465889, 'learning_rate': 9.583805209513025e-06, 'epoch': 1.64}\n",
      "{'loss': 0.0798, 'grad_norm': 3.8281569480895996, 'learning_rate': 9.513023782559455e-06, 'epoch': 1.64}\n",
      "{'loss': 0.0732, 'grad_norm': 0.07754229754209518, 'learning_rate': 9.442242355605889e-06, 'epoch': 1.65}\n",
      "{'loss': 0.286, 'grad_norm': 0.10139749199151993, 'learning_rate': 9.371460928652321e-06, 'epoch': 1.65}\n",
      "{'loss': 0.159, 'grad_norm': 0.18470674753189087, 'learning_rate': 9.300679501698755e-06, 'epoch': 1.65}\n",
      "{'loss': 0.3165, 'grad_norm': 71.72252655029297, 'learning_rate': 9.229898074745186e-06, 'epoch': 1.66}\n",
      "{'loss': 0.1359, 'grad_norm': 0.07795156538486481, 'learning_rate': 9.15911664779162e-06, 'epoch': 1.66}\n",
      "{'loss': 0.2228, 'grad_norm': 0.13452878594398499, 'learning_rate': 9.088335220838052e-06, 'epoch': 1.66}\n",
      "{'loss': 0.5733, 'grad_norm': 0.12017892301082611, 'learning_rate': 9.017553793884486e-06, 'epoch': 1.66}\n",
      "{'loss': 0.186, 'grad_norm': 0.05394025892019272, 'learning_rate': 8.946772366930918e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2115, 'grad_norm': 0.13270203769207, 'learning_rate': 8.875990939977351e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2572, 'grad_norm': 0.06895599514245987, 'learning_rate': 8.805209513023783e-06, 'epoch': 1.67}\n",
      "{'loss': 0.0703, 'grad_norm': 0.15192914009094238, 'learning_rate': 8.734428086070217e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2057, 'grad_norm': 29.806488037109375, 'learning_rate': 8.663646659116647e-06, 'epoch': 1.68}\n",
      "{'loss': 0.1713, 'grad_norm': 0.09172272682189941, 'learning_rate': 8.59286523216308e-06, 'epoch': 1.68}\n",
      "{'loss': 0.3244, 'grad_norm': 0.20176145434379578, 'learning_rate': 8.522083805209512e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0732, 'grad_norm': 0.10224472731351852, 'learning_rate': 8.451302378255946e-06, 'epoch': 1.68}\n",
      "{'loss': 0.093, 'grad_norm': 0.16070598363876343, 'learning_rate': 8.380520951302378e-06, 'epoch': 1.69}\n",
      "{'loss': 0.0997, 'grad_norm': 0.06493965536355972, 'learning_rate': 8.309739524348812e-06, 'epoch': 1.69}\n",
      "{'loss': 0.4933, 'grad_norm': 50.084720611572266, 'learning_rate': 8.238958097395244e-06, 'epoch': 1.69}\n",
      "{'loss': 0.2171, 'grad_norm': 62.47710037231445, 'learning_rate': 8.168176670441677e-06, 'epoch': 1.69}\n",
      "{'loss': 0.3141, 'grad_norm': 21.252347946166992, 'learning_rate': 8.097395243488109e-06, 'epoch': 1.7}\n",
      "{'loss': 0.0671, 'grad_norm': 1.253350853919983, 'learning_rate': 8.026613816534543e-06, 'epoch': 1.7}\n",
      "{'loss': 0.1657, 'grad_norm': 0.12973745167255402, 'learning_rate': 7.955832389580975e-06, 'epoch': 1.7}\n",
      "{'loss': 0.2424, 'grad_norm': 6.2905964851379395, 'learning_rate': 7.885050962627407e-06, 'epoch': 1.71}\n",
      "{'loss': 0.1659, 'grad_norm': 3.8346056938171387, 'learning_rate': 7.814269535673838e-06, 'epoch': 1.71}\n",
      "{'loss': 0.1088, 'grad_norm': 4.9222002029418945, 'learning_rate': 7.743488108720272e-06, 'epoch': 1.71}\n",
      "{'loss': 0.1554, 'grad_norm': 0.09182719141244888, 'learning_rate': 7.672706681766704e-06, 'epoch': 1.71}\n",
      "{'loss': 0.0733, 'grad_norm': 0.06924676895141602, 'learning_rate': 7.601925254813138e-06, 'epoch': 1.72}\n",
      "{'loss': 0.0589, 'grad_norm': 36.06837844848633, 'learning_rate': 7.53114382785957e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0797, 'grad_norm': 0.1976999044418335, 'learning_rate': 7.460362400906003e-06, 'epoch': 1.72}\n",
      "{'loss': 0.219, 'grad_norm': 0.08414406329393387, 'learning_rate': 7.389580973952436e-06, 'epoch': 1.72}\n",
      "{'loss': 0.1419, 'grad_norm': 0.0865490511059761, 'learning_rate': 7.318799546998868e-06, 'epoch': 1.73}\n",
      "{'loss': 0.066, 'grad_norm': 0.19731761515140533, 'learning_rate': 7.2480181200453006e-06, 'epoch': 1.73}\n",
      "{'loss': 0.0686, 'grad_norm': 0.07767587155103683, 'learning_rate': 7.177236693091733e-06, 'epoch': 1.73}\n",
      "{'loss': 0.2702, 'grad_norm': 180.87501525878906, 'learning_rate': 7.106455266138165e-06, 'epoch': 1.73}\n",
      "{'loss': 0.06, 'grad_norm': 110.27052307128906, 'learning_rate': 7.035673839184598e-06, 'epoch': 1.74}\n",
      "{'loss': 0.2562, 'grad_norm': 0.08172260224819183, 'learning_rate': 6.964892412231031e-06, 'epoch': 1.74}\n",
      "{'loss': 0.1413, 'grad_norm': 0.6473458409309387, 'learning_rate': 6.8941109852774636e-06, 'epoch': 1.74}\n",
      "{'loss': 0.2744, 'grad_norm': 11.785198211669922, 'learning_rate': 6.823329558323896e-06, 'epoch': 1.75}\n",
      "{'loss': 0.0634, 'grad_norm': 0.058319926261901855, 'learning_rate': 6.752548131370329e-06, 'epoch': 1.75}\n",
      "{'loss': 0.0789, 'grad_norm': 0.08967366069555283, 'learning_rate': 6.681766704416762e-06, 'epoch': 1.75}\n",
      "{'loss': 0.0817, 'grad_norm': 3.837470293045044, 'learning_rate': 6.610985277463194e-06, 'epoch': 1.75}\n",
      "{'loss': 0.029, 'grad_norm': 3.8827285766601562, 'learning_rate': 6.5402038505096265e-06, 'epoch': 1.76}\n",
      "{'loss': 0.2376, 'grad_norm': 0.05631215497851372, 'learning_rate': 6.469422423556059e-06, 'epoch': 1.76}\n",
      "{'loss': 0.3127, 'grad_norm': 0.0623144768178463, 'learning_rate': 6.398640996602492e-06, 'epoch': 1.76}\n",
      "{'loss': 0.3086, 'grad_norm': 0.0506603941321373, 'learning_rate': 6.327859569648924e-06, 'epoch': 1.76}\n",
      "{'loss': 0.2481, 'grad_norm': 65.59846496582031, 'learning_rate': 6.257078142695357e-06, 'epoch': 1.77}\n",
      "{'loss': 0.1752, 'grad_norm': 0.0634416863322258, 'learning_rate': 6.1862967157417895e-06, 'epoch': 1.77}\n",
      "{'loss': 0.3907, 'grad_norm': 3.8456923961639404, 'learning_rate': 6.115515288788222e-06, 'epoch': 1.77}\n",
      "{'loss': 0.3149, 'grad_norm': 5.639660358428955, 'learning_rate': 6.044733861834655e-06, 'epoch': 1.77}\n",
      "{'loss': 0.0879, 'grad_norm': 0.10032039135694504, 'learning_rate': 5.973952434881087e-06, 'epoch': 1.78}\n",
      "{'loss': 0.1607, 'grad_norm': 0.1059868261218071, 'learning_rate': 5.90317100792752e-06, 'epoch': 1.78}\n",
      "{'loss': 0.0575, 'grad_norm': 0.10625333338975906, 'learning_rate': 5.8323895809739525e-06, 'epoch': 1.78}\n",
      "{'loss': 0.3514, 'grad_norm': 0.13866351544857025, 'learning_rate': 5.761608154020385e-06, 'epoch': 1.78}\n",
      "{'loss': 0.1495, 'grad_norm': 0.12846288084983826, 'learning_rate': 5.690826727066818e-06, 'epoch': 1.79}\n",
      "{'loss': 0.2911, 'grad_norm': 0.15103980898857117, 'learning_rate': 5.62004530011325e-06, 'epoch': 1.79}\n",
      "{'loss': 0.3352, 'grad_norm': 0.2920962870121002, 'learning_rate': 5.549263873159683e-06, 'epoch': 1.79}\n",
      "{'loss': 0.0766, 'grad_norm': 0.7419703602790833, 'learning_rate': 5.4784824462061155e-06, 'epoch': 1.8}\n",
      "{'loss': 0.1566, 'grad_norm': 0.11993028223514557, 'learning_rate': 5.407701019252548e-06, 'epoch': 1.8}\n",
      "{'loss': 0.0063, 'grad_norm': 0.1716746836900711, 'learning_rate': 5.336919592298981e-06, 'epoch': 1.8}\n",
      "{'loss': 0.0053, 'grad_norm': 0.06743462383747101, 'learning_rate': 5.266138165345413e-06, 'epoch': 1.8}\n",
      "{'loss': 0.1363, 'grad_norm': 0.10400848090648651, 'learning_rate': 5.195356738391846e-06, 'epoch': 1.81}\n",
      "{'loss': 0.1943, 'grad_norm': 0.10008089244365692, 'learning_rate': 5.1245753114382785e-06, 'epoch': 1.81}\n",
      "{'loss': 0.1458, 'grad_norm': 0.13228867948055267, 'learning_rate': 5.053793884484711e-06, 'epoch': 1.81}\n",
      "{'loss': 0.1414, 'grad_norm': 0.05584481358528137, 'learning_rate': 4.983012457531144e-06, 'epoch': 1.81}\n",
      "{'loss': 0.2795, 'grad_norm': 0.052788425236940384, 'learning_rate': 4.912231030577576e-06, 'epoch': 1.82}\n",
      "{'loss': 0.0055, 'grad_norm': 10.764124870300293, 'learning_rate': 4.841449603624009e-06, 'epoch': 1.82}\n",
      "{'loss': 0.1569, 'grad_norm': 0.06754837185144424, 'learning_rate': 4.7706681766704415e-06, 'epoch': 1.82}\n",
      "{'loss': 0.0737, 'grad_norm': 0.08416935801506042, 'learning_rate': 4.699886749716874e-06, 'epoch': 1.82}\n",
      "{'loss': 0.3748, 'grad_norm': 5.800281524658203, 'learning_rate': 4.629105322763307e-06, 'epoch': 1.83}\n",
      "{'loss': 0.2849, 'grad_norm': 0.05246036872267723, 'learning_rate': 4.55832389580974e-06, 'epoch': 1.83}\n",
      "{'loss': 0.0857, 'grad_norm': 143.73020935058594, 'learning_rate': 4.487542468856172e-06, 'epoch': 1.83}\n",
      "{'loss': 0.2467, 'grad_norm': 0.18178081512451172, 'learning_rate': 4.4167610419026045e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0052, 'grad_norm': 0.09354439377784729, 'learning_rate': 4.345979614949037e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0852, 'grad_norm': 0.10581318289041519, 'learning_rate': 4.27519818799547e-06, 'epoch': 1.84}\n",
      "{'loss': 0.1394, 'grad_norm': 13.435445785522461, 'learning_rate': 4.204416761041903e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0663, 'grad_norm': 4.9017744064331055, 'learning_rate': 4.1336353340883355e-06, 'epoch': 1.85}\n",
      "{'loss': 0.0925, 'grad_norm': 3.8643367290496826, 'learning_rate': 4.0628539071347675e-06, 'epoch': 1.85}\n",
      "{'loss': 0.155, 'grad_norm': 0.06088372319936752, 'learning_rate': 3.9920724801812e-06, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0627, 'grad_norm': 0.047569043934345245, 'learning_rate': 3.921291053227633e-06, 'epoch': 1.85}\n",
      "{'loss': 0.1072, 'grad_norm': 0.04090407118201256, 'learning_rate': 3.850509626274066e-06, 'epoch': 1.86}\n",
      "{'loss': 0.0862, 'grad_norm': 0.24344708025455475, 'learning_rate': 3.7797281993204985e-06, 'epoch': 1.86}\n",
      "{'loss': 0.1344, 'grad_norm': 0.059452272951602936, 'learning_rate': 3.708946772366931e-06, 'epoch': 1.86}\n",
      "{'loss': 0.2669, 'grad_norm': 0.106751948595047, 'learning_rate': 3.6381653454133636e-06, 'epoch': 1.86}\n",
      "{'loss': 0.1209, 'grad_norm': 0.05449368804693222, 'learning_rate': 3.5673839184597964e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0937, 'grad_norm': 0.12965995073318481, 'learning_rate': 3.496602491506229e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0655, 'grad_norm': 6.505570411682129, 'learning_rate': 3.4258210645526615e-06, 'epoch': 1.87}\n",
      "{'loss': 0.1428, 'grad_norm': 0.06451161950826645, 'learning_rate': 3.3550396375990943e-06, 'epoch': 1.87}\n",
      "{'loss': 0.2259, 'grad_norm': 0.09031745791435242, 'learning_rate': 3.2842582106455266e-06, 'epoch': 1.88}\n",
      "{'loss': 0.0039, 'grad_norm': 0.35280972719192505, 'learning_rate': 3.2134767836919594e-06, 'epoch': 1.88}\n",
      "{'loss': 0.0832, 'grad_norm': 0.07493307441473007, 'learning_rate': 3.142695356738392e-06, 'epoch': 1.88}\n",
      "{'loss': 0.152, 'grad_norm': 0.064175084233284, 'learning_rate': 3.0719139297848245e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0043, 'grad_norm': 1.78825843334198, 'learning_rate': 3.0011325028312573e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0038, 'grad_norm': 0.062023330479860306, 'learning_rate': 2.9303510758776896e-06, 'epoch': 1.89}\n",
      "{'loss': 0.1509, 'grad_norm': 0.15105880796909332, 'learning_rate': 2.8595696489241224e-06, 'epoch': 1.89}\n",
      "{'loss': 0.0734, 'grad_norm': 3.1390397548675537, 'learning_rate': 2.788788221970555e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0663, 'grad_norm': 24.223106384277344, 'learning_rate': 2.7180067950169875e-06, 'epoch': 1.9}\n",
      "{'loss': 0.0924, 'grad_norm': 0.0520467646420002, 'learning_rate': 2.6472253680634203e-06, 'epoch': 1.9}\n",
      "{'loss': 0.1446, 'grad_norm': 0.049163900315761566, 'learning_rate': 2.5764439411098526e-06, 'epoch': 1.9}\n",
      "{'loss': 0.4665, 'grad_norm': 44.390525817871094, 'learning_rate': 2.5056625141562854e-06, 'epoch': 1.91}\n",
      "{'loss': 0.1176, 'grad_norm': 0.22341911494731903, 'learning_rate': 2.434881087202718e-06, 'epoch': 1.91}\n",
      "{'loss': 0.1952, 'grad_norm': 0.0934767872095108, 'learning_rate': 2.3640996602491505e-06, 'epoch': 1.91}\n",
      "{'loss': 0.0161, 'grad_norm': 0.5458055734634399, 'learning_rate': 2.2933182332955833e-06, 'epoch': 1.91}\n",
      "{'loss': 0.2426, 'grad_norm': 0.05569441244006157, 'learning_rate': 2.2225368063420156e-06, 'epoch': 1.92}\n",
      "{'loss': 0.1489, 'grad_norm': 0.05427645891904831, 'learning_rate': 2.1517553793884484e-06, 'epoch': 1.92}\n",
      "{'loss': 0.1787, 'grad_norm': 0.04150362312793732, 'learning_rate': 2.080973952434881e-06, 'epoch': 1.92}\n",
      "{'loss': 0.4164, 'grad_norm': 4.263725280761719, 'learning_rate': 2.0101925254813135e-06, 'epoch': 1.92}\n",
      "{'loss': 0.1031, 'grad_norm': 0.04086015745997429, 'learning_rate': 1.9394110985277462e-06, 'epoch': 1.93}\n",
      "{'loss': 0.1294, 'grad_norm': 0.14656732976436615, 'learning_rate': 1.868629671574179e-06, 'epoch': 1.93}\n",
      "{'loss': 0.2216, 'grad_norm': 0.09979402273893356, 'learning_rate': 1.7978482446206116e-06, 'epoch': 1.93}\n",
      "{'loss': 0.0049, 'grad_norm': 0.3276650607585907, 'learning_rate': 1.7270668176670443e-06, 'epoch': 1.94}\n",
      "{'loss': 0.2253, 'grad_norm': 0.045732952654361725, 'learning_rate': 1.6562853907134769e-06, 'epoch': 1.94}\n",
      "{'loss': 0.2335, 'grad_norm': 50.98181915283203, 'learning_rate': 1.5855039637599094e-06, 'epoch': 1.94}\n",
      "{'loss': 0.1874, 'grad_norm': 0.07245410233736038, 'learning_rate': 1.514722536806342e-06, 'epoch': 1.94}\n",
      "{'loss': 0.167, 'grad_norm': 0.07903873175382614, 'learning_rate': 1.4439411098527748e-06, 'epoch': 1.95}\n",
      "{'loss': 0.1557, 'grad_norm': 16.97321319580078, 'learning_rate': 1.3731596828992073e-06, 'epoch': 1.95}\n",
      "{'loss': 0.1736, 'grad_norm': 0.04912016913294792, 'learning_rate': 1.3023782559456399e-06, 'epoch': 1.95}\n",
      "{'loss': 0.1632, 'grad_norm': 22.878345489501953, 'learning_rate': 1.2315968289920724e-06, 'epoch': 1.95}\n",
      "{'loss': 0.1985, 'grad_norm': 0.059536680579185486, 'learning_rate': 1.160815402038505e-06, 'epoch': 1.96}\n",
      "{'loss': 0.1963, 'grad_norm': 0.05727531015872955, 'learning_rate': 1.0900339750849378e-06, 'epoch': 1.96}\n",
      "{'loss': 0.0971, 'grad_norm': 42.147186279296875, 'learning_rate': 1.0192525481313703e-06, 'epoch': 1.96}\n",
      "{'loss': 0.1835, 'grad_norm': 0.05419622361660004, 'learning_rate': 9.48471121177803e-07, 'epoch': 1.96}\n",
      "{'loss': 0.2528, 'grad_norm': 3.869480609893799, 'learning_rate': 8.776896942242356e-07, 'epoch': 1.97}\n",
      "{'loss': 0.1586, 'grad_norm': 0.053349923342466354, 'learning_rate': 8.069082672706682e-07, 'epoch': 1.97}\n",
      "{'loss': 0.1326, 'grad_norm': 0.06737237423658371, 'learning_rate': 7.361268403171009e-07, 'epoch': 1.97}\n",
      "{'loss': 0.1643, 'grad_norm': 0.3713759481906891, 'learning_rate': 6.653454133635334e-07, 'epoch': 1.98}\n",
      "{'loss': 0.1355, 'grad_norm': 2.1575400829315186, 'learning_rate': 5.94563986409966e-07, 'epoch': 1.98}\n",
      "{'loss': 0.2032, 'grad_norm': 0.05805739760398865, 'learning_rate': 5.237825594563986e-07, 'epoch': 1.98}\n",
      "{'loss': 0.0858, 'grad_norm': 0.1909356266260147, 'learning_rate': 4.530011325028313e-07, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1522, 'grad_norm': 0.18492259085178375, 'learning_rate': 3.822197055492639e-07, 'epoch': 1.99}\n",
      "{'loss': 0.0678, 'grad_norm': 0.08390216529369354, 'learning_rate': 3.114382785956965e-07, 'epoch': 1.99}\n",
      "{'loss': 0.1554, 'grad_norm': 0.040347158908843994, 'learning_rate': 2.406568516421291e-07, 'epoch': 1.99}\n",
      "{'loss': 0.0786, 'grad_norm': 0.06434008479118347, 'learning_rate': 1.6987542468856172e-07, 'epoch': 1.99}\n",
      "{'loss': 0.0039, 'grad_norm': 0.057423919439315796, 'learning_rate': 9.909399773499434e-08, 'epoch': 2.0}\n",
      "{'loss': 0.1146, 'grad_norm': 0.12768225371837616, 'learning_rate': 2.8312570781426955e-08, 'epoch': 2.0}\n",
      "{'train_runtime': 29141.9577, 'train_samples_per_second': 2.076, 'train_steps_per_second': 0.26, 'train_loss': 0.3215934074575417, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474ec82bc1074b2f9130661aa35802ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da avaliação: {'eval_loss': 0.18532148003578186, 'eval_runtime': 1262.057, 'eval_samples_per_second': 7.991, 'eval_steps_per_second': 0.5, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Codificação dos rótulos usando LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# Carregar o modelo DistilBERT pré-treinado para classificação de sequências\n",
    "model_name = 'distilbert-base-uncased'  # Usando DistilBERT para treinamento mais rápido\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(data['Category'].unique()))\n",
    "\n",
    "# Preparar os dados para o modelo DistilBERT\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=64, return_tensors='pt')  # Reduzido o max_length para 64\n",
    "\n",
    "# Classe personalizada para o Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # Converte para LongTensor\n",
    "        return item\n",
    "\n",
    "# Tokenizar os textos\n",
    "X_train_encodings = tokenizer(X_train.apply(lambda x: ' '.join(x)).tolist(), padding='max_length', truncation=True, max_length=64, return_tensors='pt')\n",
    "X_val_encodings = tokenizer(X_val.apply(lambda x: ' '.join(x)).tolist(), padding='max_length', truncation=True, max_length=64, return_tensors='pt')\n",
    "X_test_encodings = tokenizer(X_test.apply(lambda x: ' '.join(x)).tolist(), padding='max_length', truncation=True, max_length=64, return_tensors='pt')\n",
    "\n",
    "# Criando os datasets personalizados com os rótulos codificados\n",
    "train_dataset = CustomDataset(X_train_encodings, y_train_encoded)\n",
    "val_dataset = CustomDataset(X_val_encodings, y_val_encoded)\n",
    "\n",
    "# Definir o Trainer do Huggingface para treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Diretório para salvar os resultados\n",
    "    num_train_epochs=2,              # Número de épocas reduzido para 2\n",
    "    per_device_train_batch_size=8,   # Tamanho do lote por dispositivo (GPU/CPU)\n",
    "    per_device_eval_batch_size=16,   # Tamanho do lote de avaliação\n",
    "    warmup_steps=500,                # Número de passos para aquecimento\n",
    "    weight_decay=0.01,               # Decaimento de peso\n",
    "    logging_dir='./logs',            # Diretório para logs\n",
    "    logging_steps=10,\n",
    "    fp16=True,                       # Ativar precisão mista para acelerar em GPUs compatíveis\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # O modelo DistilBERT\n",
    "    args=training_args,                  # Argumentos de treinamento\n",
    "    train_dataset=train_dataset,         # Dados de treinamento\n",
    "    eval_dataset=val_dataset,            # Dados de validação\n",
    ")\n",
    "\n",
    "# Treinando o modelo\n",
    "trainer.train()\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Resultados da avaliação: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m new_product_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m65w\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Tokenizar a descrição do novo produto\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m new_product_encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(\n\u001b[0;32m      7\u001b[0m     new_product_description,\n\u001b[0;32m      8\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      9\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m     10\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,  \u001b[38;5;66;03m# O mesmo max_length usado no treinamento\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Retorna os tensores PyTorch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Fazer a previsão\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Descrição do novo produto\n",
    "new_product_description = \"65w\"\n",
    "\n",
    "\n",
    "# Tokenizar a descrição do novo produto\n",
    "new_product_encoding = tokenizer(\n",
    "    new_product_description,\n",
    "    padding='max_length', \n",
    "    truncation=True, \n",
    "    max_length=64,  # O mesmo max_length usado no treinamento\n",
    "    return_tensors='pt'  # Retorna os tensores PyTorch\n",
    ")\n",
    "\n",
    "# Fazer a previsão\n",
    "with torch.no_grad():\n",
    "    outputs = model(**new_product_encoding)  # Passa o dicionário de tensores\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax(-1).item()\n",
    "\n",
    "# Converter o ID previsto de volta para a categoria original\n",
    "predicted_category = label_encoder.inverse_transform([predicted_class_id])[0]\n",
    "\n",
    "print(f\"A categoria prevista para o produto é: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_14848\\2535118374.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_recall_fscore_support\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Gerar previsões no conjunto de validação\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Extrair os rótulos reais e as previsões\u001b[39;00m\n\u001b[0;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mlabel_ids\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3754\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3751\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3753\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3754\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[0;32m   3756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3757\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3867\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3864\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   3866\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 3867\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3868\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3869\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:4085\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   4083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[0;32m   4084\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 4085\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4086\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m   4088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3373\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   3371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3372\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3373\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3374\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3375\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1695\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1695\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1705\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1709\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:638\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:538\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 538\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Gerar previsões no conjunto de validação\n",
    "predictions = trainer.predict(val_dataset)\n",
    "\n",
    "# Extrair os rótulos reais e as previsões\n",
    "labels = predictions.label_ids\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "\n",
    "# Calcular as métricas\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Acurácia: {accuracy}\")\n",
    "print(f\"Precisão: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
